Namespace(dataset='cifar10', batch_size=1000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=200, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=True, magnitude_descending=False, type_mask='noisy_grad_magnitude', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=0.75, experiment_dir='benchmarking_all_exp_gc_1', out_file='benchmarking_all_exp_gc_1/0_1_noisy_grad_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_1/0_1_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=1, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=7.6171875 and C=0.75
For epoch number: 0, train loss: 2.059979799165891 and accuracy: 29.618338982370993
For epoch: 0, test loss: 1.6316011465048488 and accuracy: 51.92
For epoch number: 1, train loss: 1.4801002352526693 and accuracy: 52.51743918770362
For epoch: 1, test loss: 1.3964279301558868 and accuracy: 54.03
For epoch number: 2, train loss: 1.376226680504309 and accuracy: 54.63070806056468
For epoch: 2, test loss: 1.359872648987589 and accuracy: 55.75
For epoch number: 3, train loss: 1.344218833122217 and accuracy: 56.48972877547745
For epoch: 3, test loss: 1.3480421168894707 and accuracy: 57.06
For epoch number: 4, train loss: 1.3424817605903654 and accuracy: 57.22566460123926
For epoch: 4, test loss: 1.3237215144724785 and accuracy: 58.46
For epoch number: 5, train loss: 1.3325783537405171 and accuracy: 59.08990987030116
For epoch: 5, test loss: 1.3486652411992037 and accuracy: 59.54
For epoch number: 6, train loss: 1.3470777883983793 and accuracy: 60.43328625141743
For epoch: 6, test loss: 1.3498519161079503 and accuracy: 61.25
For epoch number: 7, train loss: 1.348864848453265 and accuracy: 61.244183001269164
For epoch: 7, test loss: 1.356281328050396 and accuracy: 61.34
For epoch number: 8, train loss: 1.3264441575648451 and accuracy: 62.409021834759656
For epoch: 8, test loss: 1.3381571037859856 and accuracy: 62.41
For epoch number: 9, train loss: 1.3399839276120862 and accuracy: 62.77104815296826
For epoch: 9, test loss: 1.3529255616513989 and accuracy: 63.14
For epoch number: 10, train loss: 1.3401367977924457 and accuracy: 63.8919681547919
For epoch: 10, test loss: 1.3450110252899459 and accuracy: 63.74
For epoch number: 11, train loss: 1.3472250948820892 and accuracy: 64.00630348486965
For epoch: 11, test loss: 1.3541201473791389 and accuracy: 64.04
For epoch number: 12, train loss: 1.3417114466146003 and accuracy: 64.69542995188372
For epoch: 12, test loss: 1.3354214724106124 and accuracy: 64.96
For epoch number: 13, train loss: 1.3345719931217341 and accuracy: 65.52300076467984
For epoch: 13, test loss: 1.3542715922186646 and accuracy: 65.38
For epoch number: 14, train loss: 1.3378247640287604 and accuracy: 66.10875310322736
For epoch: 14, test loss: 1.3481459708153447 and accuracy: 66.34
For epoch number: 15, train loss: 1.304790619979058 and accuracy: 66.86441184082177
For epoch: 15, test loss: 1.3416887672641609 and accuracy: 66.52
For epoch number: 16, train loss: 1.3286075056838629 and accuracy: 66.82235528942115
For epoch: 16, test loss: 1.3228923127621035 and accuracy: 67.14
For epoch number: 17, train loss: 1.2910866971043022 and accuracy: 67.40911621987114
For epoch: 17, test loss: 1.331344363810141 and accuracy: 67.35
For epoch number: 18, train loss: 1.312208664372026 and accuracy: 67.91577941849589
For epoch: 18, test loss: 1.323287697532509 and accuracy: 68.15
For epoch number: 19, train loss: 1.2905383233521168 and accuracy: 68.5615354174911
For epoch: 19, test loss: 1.3109854716288893 and accuracy: 68.32
For epoch number: 20, train loss: 1.291152587714996 and accuracy: 68.77133446451742
For epoch: 20, test loss: 1.315489800670479 and accuracy: 68.61
For epoch number: 21, train loss: 1.3022789092410363 and accuracy: 68.83613782051282
For epoch: 21, test loss: 1.3141765292686751 and accuracy: 68.77
For epoch number: 22, train loss: 1.2915496207462065 and accuracy: 69.24428120883069
For epoch: 22, test loss: 1.309995088396193 and accuracy: 69.09
For epoch number: 23, train loss: 1.2851682988802593 and accuracy: 69.47041745920512
For epoch: 23, test loss: 1.299722347078444 and accuracy: 69.6
For epoch number: 24, train loss: 1.2883044113601305 and accuracy: 69.88089738697303
For epoch: 24, test loss: 1.2946977803978739 and accuracy: 69.62
For epoch number: 25, train loss: 1.2822022620745546 and accuracy: 70.11328320802005
For epoch: 25, test loss: 1.2857461232173293 and accuracy: 69.98
For epoch number: 26, train loss: 1.2937026206052529 and accuracy: 69.88363041178467
For epoch: 26, test loss: 1.2942077751401104 and accuracy: 70.34
For epoch number: 27, train loss: 1.2578080993821723 and accuracy: 70.88411568319859
For epoch: 27, test loss: 1.2940982391562643 and accuracy: 70.35
For epoch number: 28, train loss: 1.2863740891614042 and accuracy: 70.72592060928685
For epoch: 28, test loss: 1.301291425771351 and accuracy: 70.38
For epoch number: 29, train loss: 1.310541505319372 and accuracy: 70.77116915323387
For epoch: 29, test loss: 1.3136331454108032 and accuracy: 70.46
For epoch number: 30, train loss: 1.3101052405036449 and accuracy: 71.22422886367269
For epoch: 30, test loss: 1.321169791342337 and accuracy: 71.1
For epoch number: 31, train loss: 1.3226609649566503 and accuracy: 71.18620189985509
For epoch: 31, test loss: 1.3253816019130658 and accuracy: 71.51
For epoch number: 32, train loss: 1.3174101963810536 and accuracy: 71.7484392508404
For epoch: 32, test loss: 1.3226542321941521 and accuracy: 71.53
For epoch number: 33, train loss: 1.3078212198865322 and accuracy: 71.94281846055827
For epoch: 33, test loss: 1.3326917728291283 and accuracy: 71.68
For epoch number: 34, train loss: 1.3514324439139593 and accuracy: 71.59890734352881
For epoch: 34, test loss: 1.3289968582648266 and accuracy: 71.84
For epoch number: 35, train loss: 1.332811396333957 and accuracy: 71.96605092361457
For epoch: 35, test loss: 1.3366075520274006 and accuracy: 72.28
For epoch number: 36, train loss: 1.3463596356120997 and accuracy: 71.68095400614322
For epoch: 36, test loss: 1.319748363917387 and accuracy: 72.35
For epoch number: 37, train loss: 1.3178747359015062 and accuracy: 72.30741439524708
For epoch: 37, test loss: 1.312313281282594 and accuracy: 72.68
For epoch number: 38, train loss: 1.331082370533393 and accuracy: 72.0
For epoch: 38, test loss: 1.3051691847511484 and accuracy: 72.65
For epoch number: 39, train loss: 1.279568207837068 and accuracy: 72.65805029556157
For epoch: 39, test loss: 1.3013040702554244 and accuracy: 72.72
For epoch number: 40, train loss: 1.3285872772853806 and accuracy: 72.3626395775386
For epoch: 40, test loss: 1.3189782198471358 and accuracy: 72.76
For epoch number: 41, train loss: 1.3000039460532593 and accuracy: 73.19134550371872
For epoch: 41, test loss: 1.3254754611208468 and accuracy: 72.71
For epoch number: 42, train loss: 1.3100666600941706 and accuracy: 72.82710700237605
For epoch: 42, test loss: 1.3165562537652027 and accuracy: 72.9
For epoch number: 43, train loss: 1.3042321439462763 and accuracy: 72.90234936870705
For epoch: 43, test loss: 1.315545747551737 and accuracy: 72.84
For epoch number: 44, train loss: 1.2948025287104197 and accuracy: 72.9204807768845
For epoch: 44, test loss: 1.3121282752556136 and accuracy: 72.94
