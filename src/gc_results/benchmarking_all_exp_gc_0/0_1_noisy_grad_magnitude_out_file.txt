Namespace(dataset='cifar10', batch_size=5000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=200, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=True, magnitude_descending=False, type_mask='noisy_grad_magnitude', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=0.75, experiment_dir='benchmarking_all_exp_gc_0', out_file='benchmarking_all_exp_gc_0/0_1_noisy_grad_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_0/0_1_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=1, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=17.03125 and C=0.75
For epoch number: 0, train loss: 2.296655383374956 and accuracy: 12.125283230735297
For epoch: 0, test loss: 2.1955454922929594 and accuracy: 21.63
For epoch number: 1, train loss: 2.0072783760237645 and accuracy: 36.381354229455496
For epoch: 1, test loss: 1.78447001342532 and accuracy: 48.77
For epoch number: 2, train loss: 1.6950806581926912 and accuracy: 50.52167494563808
For epoch: 2, test loss: 1.6043994502176213 and accuracy: 53.02
For epoch number: 3, train loss: 1.5691074381663104 and accuracy: 52.71844080348789
For epoch: 3, test loss: 1.5116984195347074 and accuracy: 54.0
For epoch number: 4, train loss: 1.4834822066656248 and accuracy: 53.97276612662757
For epoch: 4, test loss: 1.440059495877616 and accuracy: 54.86
For epoch number: 5, train loss: 1.4227556635739775 and accuracy: 54.34674318050491
For epoch: 5, test loss: 1.3997058581702317 and accuracy: 55.52
For epoch number: 6, train loss: 1.3902755891410212 and accuracy: 55.05200889312371
For epoch: 6, test loss: 1.3725556270985664 and accuracy: 55.75
For epoch number: 7, train loss: 1.3598065183477759 and accuracy: 55.78208222785214
For epoch: 7, test loss: 1.3482322240177589 and accuracy: 56.48
For epoch number: 8, train loss: 1.3490433108688582 and accuracy: 55.77588794397199
For epoch: 8, test loss: 1.330928956406026 and accuracy: 56.75
For epoch number: 9, train loss: 1.3204553041800084 and accuracy: 56.26259775860679
For epoch: 9, test loss: 1.3144724550126474 and accuracy: 56.98
For epoch number: 10, train loss: 1.3182317096408052 and accuracy: 56.481814908174286
For epoch: 10, test loss: 1.3100008919269224 and accuracy: 57.03
For epoch number: 11, train loss: 1.3046147506388406 and accuracy: 56.75502522623528
For epoch: 11, test loss: 1.302452953555916 and accuracy: 57.19
For epoch number: 12, train loss: 1.2902883710728488 and accuracy: 57.42232219968266
For epoch: 12, test loss: 1.2878879595406447 and accuracy: 57.66
For epoch number: 13, train loss: 1.284216604012204 and accuracy: 57.51139598304039
For epoch: 13, test loss: 1.2832809022710294 and accuracy: 57.9
For epoch number: 14, train loss: 1.2756148216971364 and accuracy: 57.730031756240706
For epoch: 14, test loss: 1.2740529036220116 and accuracy: 58.09
For epoch number: 15, train loss: 1.2766437846280279 and accuracy: 58.09007924566155
For epoch: 15, test loss: 1.2686905513835858 and accuracy: 58.51
For epoch number: 16, train loss: 1.2725493809369606 and accuracy: 58.175944826492795
For epoch: 16, test loss: 1.271348381344276 and accuracy: 58.7
For epoch number: 17, train loss: 1.2733297681902522 and accuracy: 58.32386193695041
For epoch: 17, test loss: 1.2728533503375477 and accuracy: 58.66
For epoch number: 18, train loss: 1.2578057379476608 and accuracy: 58.9513528669564
For epoch: 18, test loss: 1.2747951346107675 and accuracy: 58.63
For epoch number: 19, train loss: 1.2850265076509106 and accuracy: 58.18392596590114
For epoch: 19, test loss: 1.271662379367442 and accuracy: 59.13
For epoch number: 20, train loss: 1.268450483767944 and accuracy: 59.098804128651004
For epoch: 20, test loss: 1.270667453355427 and accuracy: 59.46
For epoch number: 21, train loss: 1.2630472912120632 and accuracy: 59.20633022402934
For epoch: 21, test loss: 1.2727628840675838 and accuracy: 59.7
For epoch number: 22, train loss: 1.2682306658461748 and accuracy: 59.24749130251171
For epoch: 22, test loss: 1.2711091154738317 and accuracy: 60.02
For epoch number: 23, train loss: 1.271410595478974 and accuracy: 59.69456833386429
For epoch: 23, test loss: 1.2674521698227412 and accuracy: 60.2
For epoch number: 24, train loss: 1.273169410370645 and accuracy: 59.62622069822936
For epoch: 24, test loss: 1.2658351161811925 and accuracy: 60.36
For epoch number: 25, train loss: 1.2630769685943528 and accuracy: 60.15798420157984
For epoch: 25, test loss: 1.2672078322760667 and accuracy: 60.51
For epoch number: 26, train loss: 1.2598841592817023 and accuracy: 60.58937759003824
For epoch: 26, test loss: 1.2665891602069517 and accuracy: 60.72
For epoch number: 27, train loss: 1.2527467742354923 and accuracy: 60.63323902967556
For epoch: 27, test loss: 1.2652047495298748 and accuracy: 60.87
For epoch number: 28, train loss: 1.2632219849361315 and accuracy: 60.89010791006827
For epoch: 28, test loss: 1.2676635784438894 and accuracy: 60.97
For epoch number: 29, train loss: 1.2627670824998924 and accuracy: 60.93559294903859
For epoch: 29, test loss: 1.2742118571378007 and accuracy: 61.27
For epoch number: 30, train loss: 1.2548026999624649 and accuracy: 61.41223967701963
For epoch: 30, test loss: 1.273035570036007 and accuracy: 61.34
For epoch number: 31, train loss: 1.277378971289836 and accuracy: 60.93494149127361
For epoch: 31, test loss: 1.2765233607231816 and accuracy: 61.62
For epoch number: 32, train loss: 1.2682686702536028 and accuracy: 61.41513210568455
For epoch: 32, test loss: 1.2742985917043081 and accuracy: 61.96
For epoch number: 33, train loss: 1.2711695912581078 and accuracy: 61.84482585566597
For epoch: 33, test loss: 1.2696734334849105 and accuracy: 62.11
For epoch number: 34, train loss: 1.2765113662676033 and accuracy: 61.511903328114336
For epoch: 34, test loss: 1.2690307520612885 and accuracy: 62.23
For epoch number: 35, train loss: 1.2799279753777901 and accuracy: 61.66151499337642
For epoch: 35, test loss: 1.2662851206863983 and accuracy: 62.43
For epoch number: 36, train loss: 1.264856243062587 and accuracy: 62.14509155392616
For epoch: 36, test loss: 1.2617308753955214 and accuracy: 62.43
For epoch number: 37, train loss: 1.264935222636181 and accuracy: 62.41368897835934
For epoch: 37, test loss: 1.261792774441876 and accuracy: 62.42
For epoch number: 38, train loss: 1.2688059746866396 and accuracy: 62.55582137161085
For epoch: 38, test loss: 1.2613544894170157 and accuracy: 62.64
For epoch number: 39, train loss: 1.2482366266231688 and accuracy: 63.01650403565836
For epoch: 39, test loss: 1.2627343678776222 and accuracy: 62.7
For epoch number: 40, train loss: 1.2727763693948704 and accuracy: 62.718547134493605
For epoch: 40, test loss: 1.26339706589904 and accuracy: 62.79
For epoch number: 41, train loss: 1.2736701350288087 and accuracy: 62.628571428571426
For epoch: 41, test loss: 1.2586025007163422 and accuracy: 63.08
For epoch number: 42, train loss: 1.2667917385402876 and accuracy: 63.036448560820794
For epoch: 42, test loss: 1.25244892699809 and accuracy: 63.37
For epoch number: 43, train loss: 1.2538357187887865 and accuracy: 63.42628037232542
For epoch: 43, test loss: 1.2495621669141552 and accuracy: 63.42
For epoch number: 44, train loss: 1.2534280926522394 and accuracy: 63.403310052232385
For epoch: 44, test loss: 1.2465058889570115 and accuracy: 63.65
