Namespace(dataset='cifar10', batch_size=5000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=100, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=True, magnitude_descending=False, type_mask='noisy_grad_magnitude', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=1.0, experiment_dir='benchmarking_all_exp_gc_2', out_file='benchmarking_all_exp_gc_2/0_0_noisy_grad_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_2/0_0_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=0, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=12.03125 and C=1.0
For epoch number: 0, train loss: 2.2448964904225064 and accuracy: 16.65697499548836
For epoch: 0, test loss: 1.9976251004617425 and accuracy: 38.45
For epoch number: 1, train loss: 1.8176778922261112 and accuracy: 46.895720313441835
For epoch: 1, test loss: 1.6467141169535964 and accuracy: 52.14
For epoch number: 2, train loss: 1.5831130420266404 and accuracy: 52.534562211981566
For epoch: 2, test loss: 1.5045111043543755 and accuracy: 54.32
For epoch number: 3, train loss: 1.468966905291625 and accuracy: 53.98658199120065
For epoch: 3, test loss: 1.4167006181765207 and accuracy: 55.5
For epoch number: 4, train loss: 1.3931757307897403 and accuracy: 55.16151475996422
For epoch: 4, test loss: 1.3641827951503704 and accuracy: 56.03
For epoch number: 5, train loss: 1.353145358826332 and accuracy: 55.37489788192161
For epoch: 5, test loss: 1.3397852951967264 and accuracy: 56.55
For epoch number: 6, train loss: 1.333011444518983 and accuracy: 56.09814197236779
For epoch: 6, test loss: 1.3205239863335332 and accuracy: 56.85
For epoch number: 7, train loss: 1.307703912140585 and accuracy: 56.89122065072114
For epoch: 7, test loss: 1.2981072588811946 and accuracy: 57.35
For epoch number: 8, train loss: 1.300491968593975 and accuracy: 56.884442221110554
For epoch: 8, test loss: 1.2832622663884223 and accuracy: 57.72
For epoch number: 9, train loss: 1.2735157743155718 and accuracy: 57.60501491574619
For epoch: 9, test loss: 1.2663549199888977 and accuracy: 58.11
For epoch number: 10, train loss: 1.2682084122506698 and accuracy: 57.866202536710276
For epoch: 10, test loss: 1.258371971830537 and accuracy: 58.35
For epoch number: 11, train loss: 1.2542315305225433 and accuracy: 58.254584768158885
For epoch: 11, test loss: 1.252493576158451 and accuracy: 58.73
For epoch number: 12, train loss: 1.2446910389375023 and accuracy: 58.834280664403785
For epoch: 12, test loss: 1.2470761318750019 and accuracy: 58.91
For epoch number: 13, train loss: 1.2463596980637452 and accuracy: 58.84706491231562
For epoch: 13, test loss: 1.248150876805752 and accuracy: 59.13
For epoch number: 14, train loss: 1.242145179871069 and accuracy: 58.919885838324554
For epoch: 14, test loss: 1.2420229406296452 and accuracy: 59.62
For epoch number: 15, train loss: 1.2463721812717499 and accuracy: 59.41017153174842
For epoch: 15, test loss: 1.2406802758385864 and accuracy: 59.77
For epoch number: 16, train loss: 1.2454283194044444 and accuracy: 59.555282506589506
For epoch: 16, test loss: 1.2437321800219863 and accuracy: 60.07
For epoch number: 17, train loss: 1.2460445641765934 and accuracy: 59.667803234232615
For epoch: 17, test loss: 1.24436722903312 and accuracy: 60.28
For epoch number: 18, train loss: 1.2288820307169641 and accuracy: 60.45142296368989
For epoch: 18, test loss: 1.2461492200440998 and accuracy: 60.2
For epoch number: 19, train loss: 1.2568402664934692 and accuracy: 59.82490855669485
For epoch: 19, test loss: 1.2424771370767038 and accuracy: 60.64
For epoch number: 20, train loss: 1.2382072237351471 and accuracy: 60.76583681047735
For epoch: 20, test loss: 1.2404894481731366 and accuracy: 60.99
For epoch number: 21, train loss: 1.2318372398438537 and accuracy: 60.83472853384358
For epoch: 21, test loss: 1.2413916783996775 and accuracy: 61.4
For epoch number: 22, train loss: 1.2361836992649442 and accuracy: 61.21221871417942
For epoch: 22, test loss: 1.2386208372780039 and accuracy: 61.42
For epoch number: 23, train loss: 1.238482532186771 and accuracy: 61.51242433896145
For epoch: 23, test loss: 1.235168764108344 and accuracy: 61.65
For epoch number: 24, train loss: 1.2398177535524444 and accuracy: 61.63347971685817
For epoch: 24, test loss: 1.2330458420741408 and accuracy: 61.77
For epoch number: 25, train loss: 1.2282416663547553 and accuracy: 62.05379462053794
For epoch: 25, test loss: 1.2327765090556084 and accuracy: 62.07
For epoch number: 26, train loss: 1.2239198861735883 and accuracy: 62.40315509199015
For epoch: 26, test loss: 1.2312566200389137 and accuracy: 62.23
For epoch number: 27, train loss: 1.2139216327288043 and accuracy: 62.50727342041373
For epoch: 27, test loss: 1.2288088134572477 and accuracy: 62.41
For epoch number: 28, train loss: 1.2241565496439026 and accuracy: 62.806062183427095
For epoch: 28, test loss: 1.2290465711038323 and accuracy: 62.71
For epoch number: 29, train loss: 1.221556809579902 and accuracy: 62.89441565457492
For epoch: 29, test loss: 1.232513951349862 and accuracy: 62.97
For epoch number: 30, train loss: 1.2123388576035452 and accuracy: 63.3329336051485
For epoch: 30, test loss: 1.2306638880621028 and accuracy: 63.14
For epoch number: 31, train loss: 1.2308032420965342 and accuracy: 62.93382323575223
For epoch: 31, test loss: 1.2323079629789424 and accuracy: 63.42
For epoch number: 32, train loss: 1.2200542218364745 and accuracy: 63.51281024819856
For epoch: 32, test loss: 1.230003132850309 and accuracy: 63.54
For epoch number: 33, train loss: 1.2258882943251972 and accuracy: 63.78400080297099
For epoch: 33, test loss: 1.2253457579431655 and accuracy: 63.83
For epoch number: 34, train loss: 1.2289607224473915 and accuracy: 63.44092496687944
For epoch: 34, test loss: 1.2233896745911128 and accuracy: 64.11
For epoch number: 35, train loss: 1.2329177440516281 and accuracy: 63.67668901288587
For epoch: 35, test loss: 1.2197121751459339 and accuracy: 64.31
For epoch number: 36, train loss: 1.2147096491285734 and accuracy: 64.16943951861961
For epoch: 36, test loss: 1.2148183222058453 and accuracy: 64.48
For epoch number: 37, train loss: 1.2133666611762637 and accuracy: 64.40664318067438
For epoch: 37, test loss: 1.2131768774382676 and accuracy: 64.53
For epoch number: 38, train loss: 1.217601591313379 and accuracy: 64.60326953748006
For epoch: 38, test loss: 1.2114188173149205 and accuracy: 64.64
For epoch number: 39, train loss: 1.1946746432592 and accuracy: 65.16082399710878
For epoch: 39, test loss: 1.2110113667536386 and accuracy: 64.9
For epoch number: 40, train loss: 1.2171270053767593 and accuracy: 64.69791708152455
For epoch: 40, test loss: 1.2104062422921387 and accuracy: 64.95
For epoch number: 41, train loss: 1.2173979819058423 and accuracy: 64.84611528822055
For epoch: 41, test loss: 1.206123178518271 and accuracy: 65.16
For epoch number: 42, train loss: 1.2112894681367008 and accuracy: 64.96067707293705
For epoch: 42, test loss: 1.2000031712688977 and accuracy: 65.4
For epoch number: 43, train loss: 1.196697698143904 and accuracy: 65.4833380344119
For epoch: 43, test loss: 1.196518578861333 and accuracy: 65.67
For epoch number: 44, train loss: 1.1979839101463379 and accuracy: 65.45258059997198
For epoch: 44, test loss: 1.1932146451141261 and accuracy: 65.84
For epoch number: 45, train loss: 1.1658364145652107 and accuracy: 66.5449028883965
For epoch: 45, test loss: 1.1926940226856666 and accuracy: 66.05
For epoch number: 46, train loss: 1.1788302894149507 and accuracy: 66.1526723687909
For epoch: 46, test loss: 1.1929518112653419 and accuracy: 66.22
For epoch number: 47, train loss: 1.1874646728128846 and accuracy: 65.98265199582363
For epoch: 47, test loss: 1.1915470301350461 and accuracy: 66.24
For epoch number: 48, train loss: 1.1887109626143697 and accuracy: 66.23535302954431
For epoch: 48, test loss: 1.1902971222430845 and accuracy: 66.35
For epoch number: 49, train loss: 1.1746020658858238 and accuracy: 66.54600723956563
For epoch: 49, test loss: 1.1867858578887167 and accuracy: 66.49
For epoch number: 50, train loss: 1.1762576702818928 and accuracy: 66.36687390595763
For epoch: 50, test loss: 1.1851767060122913 and accuracy: 66.75
For epoch number: 51, train loss: 1.1579996382906323 and accuracy: 66.86993500762256
For epoch: 51, test loss: 1.1827259335336806 and accuracy: 66.79
For epoch number: 52, train loss: 1.1676881028207269 and accuracy: 66.87722225532845
For epoch: 52, test loss: 1.1819265771515761 and accuracy: 66.89
For epoch number: 53, train loss: 1.173999208069983 and accuracy: 67.00357549487646
For epoch: 53, test loss: 1.1815638557265076 and accuracy: 66.88
For epoch number: 54, train loss: 1.1730677463084813 and accuracy: 66.80653798505375
For epoch: 54, test loss: 1.1783803120444092 and accuracy: 67.05
For epoch number: 55, train loss: 1.1748018425289948 and accuracy: 67.17409133644055
For epoch: 55, test loss: 1.1758272828935068 and accuracy: 66.98
For epoch number: 56, train loss: 1.1736414768756964 and accuracy: 67.0881027399992
For epoch: 56, test loss: 1.175372622435606 and accuracy: 67.14
For epoch number: 57, train loss: 1.1513714506456503 and accuracy: 67.59152292554674
For epoch: 57, test loss: 1.1761459678034238 and accuracy: 67.32
For epoch number: 58, train loss: 1.1706692262576466 and accuracy: 67.29135233860082
For epoch: 58, test loss: 1.176628161080276 and accuracy: 67.38
For epoch number: 59, train loss: 1.1640574454069137 and accuracy: 67.6947330126521
For epoch: 59, test loss: 1.1764002223558063 and accuracy: 67.47
For epoch number: 60, train loss: 1.1562356322118552 and accuracy: 67.88303673078076
For epoch: 60, test loss: 1.1757860847666293 and accuracy: 67.53
For epoch number: 61, train loss: 1.1614374653592383 and accuracy: 67.59909083658984
For epoch: 61, test loss: 1.1743945539752139 and accuracy: 67.54
For epoch number: 62, train loss: 1.1603298603898229 and accuracy: 67.94899978017146
For epoch: 62, test loss: 1.1724255250979074 and accuracy: 67.65
For epoch number: 63, train loss: 1.149443544975416 and accuracy: 68.07985018129656
For epoch: 63, test loss: 1.1713431032398078 and accuracy: 67.75
For epoch number: 64, train loss: 1.1687924664011116 and accuracy: 67.83359309435319
For epoch: 64, test loss: 1.1698803199997432 and accuracy: 67.78
For epoch number: 65, train loss: 1.1608988162085945 and accuracy: 68.00247470413315
For epoch: 65, test loss: 1.1679563084735145 and accuracy: 67.92
For epoch number: 66, train loss: 1.1634240563553158 and accuracy: 67.80286321530257
For epoch: 66, test loss: 1.1666770607610293 and accuracy: 67.91
For epoch number: 67, train loss: 1.157400040626526 and accuracy: 68.11643766722324
For epoch: 67, test loss: 1.1670684731459315 and accuracy: 67.92
For epoch number: 68, train loss: 1.1678205304962443 and accuracy: 68.08125422784609
For epoch: 68, test loss: 1.1673788141600694 and accuracy: 68.02
For epoch number: 69, train loss: 1.1607615552337995 and accuracy: 68.23602759286447
For epoch: 69, test loss: 1.1672878250291077 and accuracy: 68.1
For epoch number: 70, train loss: 1.1457819592530334 and accuracy: 68.4833230939971
For epoch: 70, test loss: 1.1674665687959405 and accuracy: 68.13
For epoch number: 71, train loss: 1.1506103099685685 and accuracy: 68.7417825411371
For epoch: 71, test loss: 1.1666275119479699 and accuracy: 68.12
For epoch number: 72, train loss: 1.1488119117591693 and accuracy: 68.58100692435097
For epoch: 72, test loss: 1.1657543008840536 and accuracy: 68.2
For epoch number: 73, train loss: 1.1480495512960442 and accuracy: 68.80733944954129
For epoch: 73, test loss: 1.1657147920584376 and accuracy: 68.28
For epoch number: 74, train loss: 1.1513778447162493 and accuracy: 68.86905475020966
For epoch: 74, test loss: 1.1646156914626495 and accuracy: 68.35
For epoch number: 75, train loss: 1.1504236078729817 and accuracy: 68.59854564187917
For epoch: 75, test loss: 1.16269517171232 and accuracy: 68.45
For epoch number: 76, train loss: 1.1542520159342158 and accuracy: 68.6110779752674
For epoch: 76, test loss: 1.1613077408150783 and accuracy: 68.45
For epoch number: 77, train loss: 1.1456563981625403 and accuracy: 68.57638542684508
For epoch: 77, test loss: 1.1605340506457076 and accuracy: 68.47
For epoch number: 78, train loss: 1.1589600417924963 and accuracy: 68.7124138755028
For epoch: 78, test loss: 1.160472973992553 and accuracy: 68.49
For epoch number: 79, train loss: 1.1563112700617852 and accuracy: 68.69407521074552
For epoch: 79, test loss: 1.1602057180827177 and accuracy: 68.55
For epoch number: 80, train loss: 1.153120410582874 and accuracy: 68.75607096838141
For epoch: 80, test loss: 1.159463976757436 and accuracy: 68.59
For epoch number: 81, train loss: 1.1475140973777467 and accuracy: 68.78117457763476
For epoch: 81, test loss: 1.1586603258229509 and accuracy: 68.56
For epoch number: 82, train loss: 1.1382801472669533 and accuracy: 68.98117585868891
For epoch: 82, test loss: 1.1579494121708447 and accuracy: 68.57
For epoch number: 83, train loss: 1.1576231735838098 and accuracy: 68.65160848733744
For epoch: 83, test loss: 1.1576926187623906 and accuracy: 68.55
For epoch number: 84, train loss: 1.1521889834120722 and accuracy: 68.9080010424811
For epoch: 84, test loss: 1.1572983114025261 and accuracy: 68.58
For epoch number: 85, train loss: 1.138672224264371 and accuracy: 69.22461870589882
For epoch: 85, test loss: 1.156884738161594 and accuracy: 68.65
For epoch number: 86, train loss: 1.1511364653854674 and accuracy: 69.09866944533505
For epoch: 86, test loss: 1.1565801961512505 and accuracy: 68.68
For epoch number: 87, train loss: 1.149368936580325 and accuracy: 69.03727143457972
For epoch: 87, test loss: 1.1561311128773266 and accuracy: 68.69
For epoch number: 88, train loss: 1.1375068270948512 and accuracy: 68.9761017320763
For epoch: 88, test loss: 1.1558023645908018 and accuracy: 68.74
For epoch number: 89, train loss: 1.1330992164819136 and accuracy: 69.20063948840927
For epoch: 89, test loss: 1.1558109091807016 and accuracy: 68.74
For epoch number: 90, train loss: 1.1462940710605962 and accuracy: 69.09010883482715
For epoch: 90, test loss: 1.1557924234414403 and accuracy: 68.73
For epoch number: 91, train loss: 1.1413184590199414 and accuracy: 69.10100065649432
For epoch: 91, test loss: 1.155811816076689 and accuracy: 68.73
For epoch number: 92, train loss: 1.1404352427235704 and accuracy: 69.21967633392084
For epoch: 92, test loss: 1.1557876754410659 and accuracy: 68.74
For epoch number: 93, train loss: 1.1543894082249264 and accuracy: 68.83818911721451
For epoch: 93, test loss: 1.1557375494437883 and accuracy: 68.74
For epoch number: 94, train loss: 1.158060067927624 and accuracy: 68.7045240433763
For epoch: 94, test loss: 1.155726121950753 and accuracy: 68.76
For epoch number: 95, train loss: 1.1417412065043309 and accuracy: 69.0380501069722
For epoch: 95, test loss: 1.1556985227367547 and accuracy: 68.76
For epoch number: 96, train loss: 1.1329903687580978 and accuracy: 69.23061554751963
For epoch: 96, test loss: 1.155676834190948 and accuracy: 68.76
For epoch number: 97, train loss: 1.1411768103214666 and accuracy: 69.14806286915608
For epoch: 97, test loss: 1.1556612577619432 and accuracy: 68.75
For epoch number: 98, train loss: 1.1456153913020155 and accuracy: 68.86150559753155
For epoch: 98, test loss: 1.1556525698191003 and accuracy: 68.75
For epoch number: 99, train loss: 1.1322394207767819 and accuracy: 69.240298924989
For epoch: 99, test loss: 1.155651690084723 and accuracy: 68.75
Test accuracy: 68.75
