Namespace(dataset='cifar10', batch_size=5000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=100, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=False, magnitude_descending=False, type_mask='', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=1.0, experiment_dir='benchmarking_all_exp_gc_2', out_file='benchmarking_all_exp_gc_2/0_0_smallest_fixed_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_2/0_0_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=0, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=12.03125 and C=1.0
For epoch number: 0, train loss: 2.2448964904225064 and accuracy: 16.65697499548836
For epoch: 0, test loss: 1.9976251004617425 and accuracy: 38.45
For epoch number: 1, train loss: 1.8176778922261112 and accuracy: 46.895720313441835
For epoch: 1, test loss: 1.6467141169535964 and accuracy: 52.14
For epoch number: 2, train loss: 1.5831130420266404 and accuracy: 52.534562211981566
For epoch: 2, test loss: 1.5045111043543755 and accuracy: 54.32
For epoch number: 3, train loss: 1.468966905291625 and accuracy: 53.98658199120065
For epoch: 3, test loss: 1.4167006181765207 and accuracy: 55.5
For epoch number: 4, train loss: 1.3931757307897403 and accuracy: 55.16151475996422
For epoch: 4, test loss: 1.3641827951503704 and accuracy: 56.03
For epoch number: 5, train loss: 1.353145358826332 and accuracy: 55.37489788192161
For epoch: 5, test loss: 1.3397852951967264 and accuracy: 56.55
For epoch number: 6, train loss: 1.333011444518983 and accuracy: 56.09814197236779
For epoch: 6, test loss: 1.3205239863335332 and accuracy: 56.85
For epoch number: 7, train loss: 1.307703912140585 and accuracy: 56.89122065072114
For epoch: 7, test loss: 1.2981072588811946 and accuracy: 57.35
For epoch number: 8, train loss: 1.300491968593975 and accuracy: 56.884442221110554
For epoch: 8, test loss: 1.2832622663884223 and accuracy: 57.72
For epoch number: 9, train loss: 1.2735157743155718 and accuracy: 57.60501491574619
For epoch: 9, test loss: 1.2663549199888977 and accuracy: 58.11
For epoch number: 10, train loss: 1.2672650742058706 and accuracy: 57.94822550314088
For epoch: 10, test loss: 1.258219076108329 and accuracy: 58.45
For epoch number: 11, train loss: 1.2538331484510785 and accuracy: 58.45279090253864
For epoch: 11, test loss: 1.2544706184652787 and accuracy: 58.87
For epoch number: 12, train loss: 1.2451544835363657 and accuracy: 59.03311976541003
For epoch: 12, test loss: 1.2496347216111194 and accuracy: 58.85
For epoch number: 13, train loss: 1.2463424134207524 and accuracy: 59.079960984931425
For epoch: 13, test loss: 1.2514124165607403 and accuracy: 59.15
For epoch number: 14, train loss: 1.243374532912357 and accuracy: 59.21734935884552
For epoch: 14, test loss: 1.2457032279123235 and accuracy: 59.85
For epoch number: 15, train loss: 1.2483935311200127 and accuracy: 59.68903601163607
For epoch: 15, test loss: 1.2434513998937002 and accuracy: 59.9
For epoch number: 16, train loss: 1.2459684665512851 and accuracy: 59.80300838304366
For epoch: 16, test loss: 1.2454066683974447 and accuracy: 60.21
For epoch number: 17, train loss: 1.2477629975924596 and accuracy: 60.084544675081254
For epoch: 17, test loss: 1.2461480686936197 and accuracy: 60.61
For epoch number: 18, train loss: 1.2302249089356452 and accuracy: 60.7518375357994
For epoch: 18, test loss: 1.2485820907580703 and accuracy: 60.63
For epoch number: 19, train loss: 1.2586133046583696 and accuracy: 60.25064460034778
For epoch: 19, test loss: 1.245756308489208 and accuracy: 61.06
For epoch number: 20, train loss: 1.2412580627896612 and accuracy: 61.081275329912756
For epoch: 20, test loss: 1.2451194275783588 and accuracy: 61.35
For epoch number: 21, train loss: 1.2347376542919015 and accuracy: 61.3529458662202
For epoch: 21, test loss: 1.2461876590040666 and accuracy: 61.71
For epoch number: 22, train loss: 1.2393956173701115 and accuracy: 61.56011824562109
For epoch: 22, test loss: 1.2437220789209198 and accuracy: 62.01
For epoch number: 23, train loss: 1.2420914987410148 and accuracy: 61.91860465116279
For epoch: 23, test loss: 1.2413315908818305 and accuracy: 62.18
For epoch number: 24, train loss: 1.2441084115278154 and accuracy: 62.024504201006636
For epoch: 24, test loss: 1.239283151264432 and accuracy: 62.29
For epoch number: 25, train loss: 1.2328309944360563 and accuracy: 62.50374962503749
For epoch: 25, test loss: 1.2397618512564068 and accuracy: 62.54
For epoch number: 26, train loss: 1.2289964024383242 and accuracy: 62.99973974495005
For epoch: 26, test loss: 1.2388658116135416 and accuracy: 62.75
For epoch number: 27, train loss: 1.2188466408143697 and accuracy: 63.10118581833504
For epoch: 27, test loss: 1.2365243608438516 and accuracy: 63.1
For epoch number: 28, train loss: 1.2286928190834938 and accuracy: 63.390658471641075
For epoch: 28, test loss: 1.2366330699075627 and accuracy: 63.46
For epoch number: 29, train loss: 1.22692115092466 and accuracy: 63.630724904459875
For epoch: 29, test loss: 1.2394217614886127 and accuracy: 63.69
For epoch number: 30, train loss: 1.2174708516290873 and accuracy: 64.01646880121517
For epoch: 30, test loss: 1.2373876111416877 and accuracy: 63.95
For epoch number: 31, train loss: 1.236444743074609 and accuracy: 63.652701785215065
For epoch: 31, test loss: 1.239936057525345 and accuracy: 64.09
For epoch number: 32, train loss: 1.2273593596790149 and accuracy: 64.22738190552442
For epoch: 32, test loss: 1.2391739902617056 and accuracy: 64.32
For epoch number: 33, train loss: 1.2337037458808475 and accuracy: 64.47857071163304
For epoch: 33, test loss: 1.2356482932839212 and accuracy: 64.67
For epoch number: 34, train loss: 1.234829464044229 and accuracy: 64.17760648761492
For epoch: 34, test loss: 1.2344101591955257 and accuracy: 64.88
For epoch number: 35, train loss: 1.2416405484643183 and accuracy: 64.50764722411786
For epoch: 35, test loss: 1.2318839732604692 and accuracy: 64.98
For epoch number: 36, train loss: 1.223074325020351 and accuracy: 64.84488632967383
For epoch: 36, test loss: 1.2261822910248479 and accuracy: 65.27
For epoch number: 37, train loss: 1.2202180132447962 and accuracy: 65.35279315551082
For epoch: 37, test loss: 1.2246278720565988 and accuracy: 65.38
For epoch number: 38, train loss: 1.2280893505677668 and accuracy: 65.25318979266348
For epoch: 38, test loss: 1.2236009383503395 and accuracy: 65.44
For epoch number: 39, train loss: 1.2065971427493625 and accuracy: 65.80934024013172
For epoch: 39, test loss: 1.2240249001527135 and accuracy: 65.61
For epoch number: 40, train loss: 1.2271467022877003 and accuracy: 65.42474809829145
For epoch: 40, test loss: 1.223440646370755 and accuracy: 65.76
For epoch number: 41, train loss: 1.2269167919082946 and accuracy: 65.68020050125314
For epoch: 41, test loss: 1.218764975855622 and accuracy: 66.01
For epoch number: 42, train loss: 1.221983883102892 and accuracy: 65.80102998123678
For epoch: 42, test loss: 1.2121900621848771 and accuracy: 66.23
For epoch number: 43, train loss: 1.2076542416732468 and accuracy: 66.0978361606963
For epoch: 43, test loss: 1.208978430379795 and accuracy: 66.41
For epoch number: 44, train loss: 1.2077828412264526 and accuracy: 66.05295283075507
For epoch: 44, test loss: 1.2056617593463463 and accuracy: 66.54
For epoch number: 45, train loss: 1.1766735065595906 and accuracy: 67.24354751781544
For epoch: 45, test loss: 1.2057152677185927 and accuracy: 66.7
For epoch number: 46, train loss: 1.1917213104547015 and accuracy: 66.7168614223186
For epoch: 46, test loss: 1.2064656939687608 and accuracy: 66.72
For epoch number: 47, train loss: 1.2033158011038307 and accuracy: 66.52477712633524
For epoch: 47, test loss: 1.2060476488704923 and accuracy: 66.85
For epoch number: 48, train loss: 1.1995827497707472 and accuracy: 66.99449173760641
For epoch: 48, test loss: 1.2054727779159062 and accuracy: 66.89
For epoch number: 49, train loss: 1.1868949572718333 and accuracy: 67.1479711217327
For epoch: 49, test loss: 1.202715809586682 and accuracy: 67.02
For epoch number: 50, train loss: 1.1928452318645568 and accuracy: 67.17571075028671
For epoch: 50, test loss: 1.2016792606703843 and accuracy: 67.18
For epoch number: 51, train loss: 1.1755938559534058 and accuracy: 67.37944315172912
For epoch: 51, test loss: 1.1994143754621096 and accuracy: 67.34
For epoch number: 52, train loss: 1.1795292497854533 and accuracy: 67.4949844069682
For epoch: 52, test loss: 1.1985520071621183 and accuracy: 67.42
For epoch number: 53, train loss: 1.186026335945205 and accuracy: 67.65076004234665
For epoch: 53, test loss: 1.1990217445771905 and accuracy: 67.56
For epoch number: 54, train loss: 1.186989263112366 and accuracy: 67.50589457698916
For epoch: 54, test loss: 1.19682147306732 and accuracy: 67.63
For epoch number: 55, train loss: 1.192873215557325 and accuracy: 67.69618531335641
For epoch: 55, test loss: 1.1945863019061993 and accuracy: 67.71
For epoch number: 56, train loss: 1.1909850235051187 and accuracy: 67.66441989390978
For epoch: 56, test loss: 1.1940400215643872 and accuracy: 67.81
