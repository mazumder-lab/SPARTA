Namespace(dataset='cifar10', batch_size=5000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=100, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=True, magnitude_descending=False, type_mask='noisy_grad_magnitude', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=0.75, experiment_dir='benchmarking_all_exp_gc_2', out_file='benchmarking_all_exp_gc_2/0_1_noisy_grad_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_2/0_1_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=1, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=12.03125 and C=0.75
For epoch number: 0, train loss: 2.26238095854956 and accuracy: 15.110986344769506
For epoch: 0, test loss: 2.065678198126298 and accuracy: 33.03
For epoch number: 1, train loss: 1.9014439990458858 and accuracy: 43.61060880048222
For epoch: 1, test loss: 1.7325821028480046 and accuracy: 50.44
For epoch number: 2, train loss: 1.6659293323166287 and accuracy: 51.533105910986095
For epoch: 2, test loss: 1.588091657131533 and accuracy: 53.62
For epoch number: 3, train loss: 1.5543061027846 and accuracy: 53.214150624116584
For epoch: 3, test loss: 1.4972297466253932 and accuracy: 54.56
For epoch number: 4, train loss: 1.4704331593719993 and accuracy: 54.25504423019581
For epoch: 4, test loss: 1.4277881097189988 and accuracy: 55.42
For epoch number: 5, train loss: 1.4115095817053271 and accuracy: 54.59182656863331
For epoch: 5, test loss: 1.3876960247377805 and accuracy: 55.92
For epoch number: 6, train loss: 1.3787244808931483 and accuracy: 55.42520247737018
For epoch: 6, test loss: 1.360155034668838 and accuracy: 56.24
For epoch number: 7, train loss: 1.3485478172170575 and accuracy: 56.127191845039796
For epoch: 7, test loss: 1.3361581081076512 and accuracy: 56.64
For epoch number: 8, train loss: 1.3380456876046587 and accuracy: 56.11605802901451
For epoch: 8, test loss: 1.319191146500503 and accuracy: 56.93
For epoch number: 9, train loss: 1.3108316625494405 and accuracy: 56.64355397887608
For epoch: 9, test loss: 1.3045653165141238 and accuracy: 57.19
For epoch number: 10, train loss: 1.3085079703000513 and accuracy: 56.86792301844516
For epoch: 10, test loss: 1.2981841247293013 and accuracy: 57.23
For epoch number: 11, train loss: 1.2931691700267414 and accuracy: 57.085368783534875
For epoch: 11, test loss: 1.2898247438141062 and accuracy: 57.55
For epoch number: 12, train loss: 1.2793706332001962 and accuracy: 57.679407097953366
For epoch: 12, test loss: 1.2772391793094104 and accuracy: 57.99
For epoch number: 13, train loss: 1.2747775094480964 and accuracy: 57.772159961781156
For epoch: 13, test loss: 1.2721233201932303 and accuracy: 58.15
For epoch number: 14, train loss: 1.266457261079811 and accuracy: 57.8586646299795
For epoch: 14, test loss: 1.2643825751316697 and accuracy: 58.49
For epoch number: 15, train loss: 1.2683378300733037 and accuracy: 58.391012137626646
For epoch: 15, test loss: 1.260215686846383 and accuracy: 58.77
For epoch number: 16, train loss: 1.264617728553419 and accuracy: 58.312689510295485
For epoch: 16, test loss: 1.2617846078510526 and accuracy: 59.0
For epoch number: 17, train loss: 1.2650623646008192 and accuracy: 58.373711391597375
For epoch: 17, test loss: 1.2626468908937671 and accuracy: 59.01
For epoch number: 18, train loss: 1.248852127009914 and accuracy: 59.17766517794556
For epoch: 18, test loss: 1.2638950755324545 and accuracy: 59.01
For epoch number: 19, train loss: 1.2760902501848848 and accuracy: 58.40778717195339
For epoch: 19, test loss: 1.2616004242172725 and accuracy: 59.29
For epoch number: 20, train loss: 1.260230106244661 and accuracy: 59.28048074427519
For epoch: 20, test loss: 1.2608417257477966 and accuracy: 59.54
For epoch number: 21, train loss: 1.254839348487365 and accuracy: 59.33588455712349
For epoch: 21, test loss: 1.2623588767232774 and accuracy: 59.85
For epoch number: 22, train loss: 1.2602826700030094 and accuracy: 59.48076497677318
For epoch: 22, test loss: 1.2610753397398358 and accuracy: 60.18
For epoch number: 23, train loss: 1.2639540823425834 and accuracy: 59.851863650844216
For epoch: 23, test loss: 1.2589449807058406 and accuracy: 60.37
For epoch number: 24, train loss: 1.266437451990824 and accuracy: 59.80268302953739
For epoch: 24, test loss: 1.257565231262883 and accuracy: 60.48
For epoch number: 25, train loss: 1.255734602531584 and accuracy: 60.355964403559646
For epoch: 25, test loss: 1.2579925912844985 and accuracy: 60.8
For epoch number: 26, train loss: 1.2528405621500298 and accuracy: 60.74152669616224
For epoch: 26, test loss: 1.2577597996856593 and accuracy: 60.85
For epoch number: 27, train loss: 1.2456291880806682 and accuracy: 60.73556853066875
For epoch: 27, test loss: 1.256689494169211 and accuracy: 61.01
For epoch number: 28, train loss: 1.2560280446731855 and accuracy: 60.97619571963403
For epoch: 28, test loss: 1.2578781156600276 and accuracy: 61.19
For epoch number: 29, train loss: 1.253318770600873 and accuracy: 61.09566017727445
For epoch: 29, test loss: 1.2619290646118453 and accuracy: 61.33
For epoch number: 30, train loss: 1.244921868154318 and accuracy: 61.49018667306232
For epoch: 30, test loss: 1.2618449013444442 and accuracy: 61.5
For epoch number: 31, train loss: 1.2669561796874924 and accuracy: 61.02679819481609
For epoch: 31, test loss: 1.2637932677812214 and accuracy: 61.7
For epoch number: 32, train loss: 1.25718180311056 and accuracy: 61.55524419535629
For epoch: 32, test loss: 1.2620798605906813 and accuracy: 62.01
For epoch number: 33, train loss: 1.26031162463884 and accuracy: 61.93516009234166
For epoch: 33, test loss: 1.2589694276640686 and accuracy: 62.18
For epoch number: 34, train loss: 1.2661277818014898 and accuracy: 61.58617367216669
For epoch: 34, test loss: 1.2581513093996652 and accuracy: 62.33
For epoch number: 35, train loss: 1.2696139493709055 and accuracy: 61.70767933844486
For epoch: 35, test loss: 1.2561293697055382 and accuracy: 62.45
For epoch number: 36, train loss: 1.2550482812618453 and accuracy: 62.18892586024826
For epoch: 36, test loss: 1.2527891223943686 and accuracy: 62.53
For epoch number: 37, train loss: 1.2561012031547576 and accuracy: 62.38953195772521
For epoch: 37, test loss: 1.2520444596870035 and accuracy: 62.51
For epoch number: 38, train loss: 1.2596047199689424 and accuracy: 62.5817384370016
For epoch: 38, test loss: 1.2510925999170617 and accuracy: 62.73
For epoch number: 39, train loss: 1.239210726486312 and accuracy: 62.98237160181504
For epoch: 39, test loss: 1.2514659664298915 and accuracy: 62.79
For epoch number: 40, train loss: 1.2621630461963675 and accuracy: 62.73846031303517
For epoch: 40, test loss: 1.2519783800161337 and accuracy: 62.87
For epoch number: 41, train loss: 1.2638193111258198 and accuracy: 62.64661654135338
For epoch: 41, test loss: 1.2493342485608934 and accuracy: 63.11
For epoch number: 42, train loss: 1.2590041259531919 and accuracy: 62.94662461575312
For epoch: 42, test loss: 1.2449757886838309 and accuracy: 63.23
For epoch number: 43, train loss: 1.245869354692524 and accuracy: 63.263085787967924
For epoch: 43, test loss: 1.2422878983654553 and accuracy: 63.41
For epoch number: 44, train loss: 1.2466780545697298 and accuracy: 63.349276551461905
For epoch: 44, test loss: 1.2395171176029156 and accuracy: 63.52
