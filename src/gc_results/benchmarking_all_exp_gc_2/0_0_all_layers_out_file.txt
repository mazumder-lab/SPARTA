Namespace(dataset='cifar10', batch_size=5000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=100, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=False, use_adaptive_magnitude_mask=False, magnitude_descending=False, type_mask='', sparsity=0.0, use_dp=True, epsilon=1.0, delta=1e-05, clipping=1.0, experiment_dir='benchmarking_all_exp_gc_2', out_file='benchmarking_all_exp_gc_2/0_0_all_layers_out_file.txt', save_file='benchmarking_all_exp_gc_2/0_0_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=0, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61].
The names of trainable parameters are: ['conv1.weight', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=12.03125 and C=1.0
For epoch number: 0, train loss: 2.2592854763679355 and accuracy: 14.883200447615051
For epoch: 0, test loss: 2.0596678332437444 and accuracy: 31.22
For epoch number: 1, train loss: 1.9029053475494686 and accuracy: 42.184478599764766
For epoch: 1, test loss: 1.7380093426644048 and accuracy: 50.22
For epoch number: 2, train loss: 1.6697056446622012 and accuracy: 51.480542299782364
For epoch: 2, test loss: 1.5880460648597041 and accuracy: 53.53
For epoch number: 3, train loss: 1.5439580074663934 and accuracy: 53.33852481929635
For epoch: 3, test loss: 1.4869463881359826 and accuracy: 54.93
For epoch number: 4, train loss: 1.4524505828680256 and accuracy: 55.20245618931797
For epoch: 4, test loss: 1.4125353082825867 and accuracy: 55.67
For epoch number: 5, train loss: 1.395725996783429 and accuracy: 55.64999498847349
For epoch: 5, test loss: 1.3677390119697475 and accuracy: 56.79
For epoch number: 6, train loss: 1.3587876511092234 and accuracy: 56.38771800147831
For epoch: 6, test loss: 1.3365948049327996 and accuracy: 57.22
For epoch number: 7, train loss: 1.3280595713322705 and accuracy: 56.87294852293651
For epoch: 7, test loss: 1.3082971874671647 and accuracy: 57.82
For epoch number: 8, train loss: 1.3063177618649926 and accuracy: 57.355441326479585
For epoch: 8, test loss: 1.288841793808756 and accuracy: 58.41
For epoch number: 9, train loss: 1.2774723496979583 and accuracy: 58.09491280237885
For epoch: 9, test loss: 1.2656197502643247 and accuracy: 58.92
For epoch number: 10, train loss: 1.2562973259699226 and accuracy: 58.7441432061191
For epoch: 10, test loss: 1.252022792266894 and accuracy: 59.53
For epoch number: 11, train loss: 1.249873947743142 and accuracy: 59.268929503916446
For epoch: 11, test loss: 1.2368199870556216 and accuracy: 59.9
For epoch number: 12, train loss: 1.2359368768134136 and accuracy: 59.61450114850694
For epoch: 12, test loss: 1.2193876293641102 and accuracy: 60.29
For epoch number: 13, train loss: 1.2201523757263606 and accuracy: 60.09702729142127
For epoch: 13, test loss: 1.2122893499422678 and accuracy: 60.45
For epoch number: 14, train loss: 1.205393327686363 and accuracy: 60.340514806745745
For epoch: 14, test loss: 1.2039414961126786 and accuracy: 60.98
For epoch number: 15, train loss: 1.1858658789405747 and accuracy: 61.350160256410255
For epoch: 15, test loss: 1.1971358951134017 and accuracy: 61.33
For epoch number: 16, train loss: 1.1840496256830186 and accuracy: 62.00215070893739
For epoch: 16, test loss: 1.1959415357324141 and accuracy: 61.84
For epoch number: 17, train loss: 1.1910666311986349 and accuracy: 62.19701801945463
For epoch: 17, test loss: 1.1945307805568357 and accuracy: 62.34
For epoch number: 18, train loss: 1.189880762175609 and accuracy: 62.25268795715257
For epoch: 18, test loss: 1.1980820962145358 and accuracy: 62.45
For epoch number: 19, train loss: 1.1921134281299801 and accuracy: 62.53161531874216
For epoch: 19, test loss: 1.1964479639560361 and accuracy: 62.8
For epoch number: 20, train loss: 1.1986606202342294 and accuracy: 62.68695513076862
For epoch: 20, test loss: 1.1967434121083609 and accuracy: 63.1
For epoch number: 21, train loss: 1.1910264066626015 and accuracy: 63.25835720151421
For epoch: 21, test loss: 1.1961571287505235 and accuracy: 63.52
For epoch number: 22, train loss: 1.1820887946846461 and accuracy: 63.45392764341395
For epoch: 22, test loss: 1.1962238384198538 and accuracy: 63.7
For epoch number: 23, train loss: 1.184812579937132 and accuracy: 63.74250299880048
For epoch: 23, test loss: 1.1960550591915469 and accuracy: 63.87
For epoch number: 24, train loss: 1.1974566354609952 and accuracy: 63.9906375657671
For epoch: 24, test loss: 1.1944614988339097 and accuracy: 64.11
For epoch number: 25, train loss: 1.1958876919178736 and accuracy: 64.31596908561679
For epoch: 25, test loss: 1.1954966534542133 and accuracy: 64.39
For epoch number: 26, train loss: 1.1877880597114563 and accuracy: 64.74206429234059
For epoch: 26, test loss: 1.1914969878860666 and accuracy: 64.89
For epoch number: 27, train loss: 1.1801908242372656 and accuracy: 65.13039658133312
For epoch: 27, test loss: 1.1884593065780928 and accuracy: 65.24
For epoch number: 28, train loss: 1.1794540367182895 and accuracy: 65.5188227787526
For epoch: 28, test loss: 1.1873749901976767 and accuracy: 65.57
For epoch number: 29, train loss: 1.1746827433330302 and accuracy: 65.81457535121328
For epoch: 29, test loss: 1.1877008186110967 and accuracy: 65.94
For epoch number: 30, train loss: 1.1716377084690428 and accuracy: 66.28452318916102
For epoch: 30, test loss: 1.1851858232594743 and accuracy: 66.29
For epoch number: 31, train loss: 1.1622475335797466 and accuracy: 66.6479110986074
For epoch: 31, test loss: 1.1864142417907715 and accuracy: 66.63
For epoch number: 32, train loss: 1.17899567266502 and accuracy: 66.66400558826464
For epoch: 32, test loss: 1.1868236344071883 and accuracy: 66.73
For epoch number: 33, train loss: 1.1861332140670382 and accuracy: 66.80239905321646
For epoch: 33, test loss: 1.1828845015055016 and accuracy: 67.02
For epoch number: 34, train loss: 1.1640366240303115 and accuracy: 67.38987114174408
For epoch: 34, test loss: 1.181158206130885 and accuracy: 67.23
For epoch number: 35, train loss: 1.1606513636385498 and accuracy: 67.85414752985344
For epoch: 35, test loss: 1.1798976591870756 and accuracy: 67.38
For epoch number: 36, train loss: 1.1651857186683081 and accuracy: 67.85341993424746
For epoch: 36, test loss: 1.1725293201736258 and accuracy: 67.69
For epoch number: 37, train loss: 1.1643698929326807 and accuracy: 67.72010826301545
For epoch: 37, test loss: 1.170229794858377 and accuracy: 67.86
For epoch number: 38, train loss: 1.1433095431374938 and accuracy: 68.58819537316114
For epoch: 38, test loss: 1.1705933816825287 and accuracy: 68.07
For epoch number: 39, train loss: 1.1553066756885513 and accuracy: 68.56139230400767
For epoch: 39, test loss: 1.1714956247353856 and accuracy: 68.35
For epoch number: 40, train loss: 1.1493615718862162 and accuracy: 68.6209776858518
For epoch: 40, test loss: 1.1713215308853342 and accuracy: 68.5
For epoch number: 41, train loss: 1.1579854927129216 and accuracy: 68.58093882216117
For epoch: 41, test loss: 1.1673248417769806 and accuracy: 68.76
For epoch number: 42, train loss: 1.1428401294806843 and accuracy: 69.03211543872342
For epoch: 42, test loss: 1.1613539834565754 and accuracy: 69.01
For epoch number: 43, train loss: 1.1385686035203462 and accuracy: 69.25453378269941
For epoch: 43, test loss: 1.1589263647417478 and accuracy: 69.32
For epoch number: 44, train loss: 1.1519914967976068 and accuracy: 69.09275963917938
For epoch: 44, test loss: 1.1550136593323719 and accuracy: 69.56
For epoch number: 45, train loss: 1.1316151462850117 and accuracy: 69.61552368325901
For epoch: 45, test loss: 1.1558801388438744 and accuracy: 69.56
For epoch number: 46, train loss: 1.130023751400485 and accuracy: 69.84447465216697
For epoch: 46, test loss: 1.1584450964686237 and accuracy: 69.54
For epoch number: 47, train loss: 1.1374957769278036 and accuracy: 69.92182004542074
For epoch: 47, test loss: 1.1572159000589877 and accuracy: 69.76
For epoch number: 48, train loss: 1.129740856028357 and accuracy: 69.95606151388057
For epoch: 48, test loss: 1.1552507764176478 and accuracy: 69.93
For epoch number: 49, train loss: 1.118639766931056 and accuracy: 70.5947625388371
For epoch: 49, test loss: 1.1520239642903776 and accuracy: 70.14
For epoch number: 50, train loss: 1.1215822500002457 and accuracy: 70.49163730611915
For epoch: 50, test loss: 1.1489004522939272 and accuracy: 70.21
For epoch number: 51, train loss: 1.1394946440877651 and accuracy: 70.27959476707083
For epoch: 51, test loss: 1.1444342898417124 and accuracy: 70.38
For epoch number: 52, train loss: 1.1250101343239889 and accuracy: 70.57203305257275
For epoch: 52, test loss: 1.1419918672947944 and accuracy: 70.6
For epoch number: 53, train loss: 1.1180257882305724 and accuracy: 70.68888978570564
For epoch: 53, test loss: 1.140770349321486 and accuracy: 70.64
For epoch number: 54, train loss: 1.1111787873435306 and accuracy: 71.09655906634795
For epoch: 54, test loss: 1.1388054037395912 and accuracy: 70.86
For epoch number: 55, train loss: 1.108377398468378 and accuracy: 71.0416791126511
For epoch: 55, test loss: 1.1367513386509087 and accuracy: 71.0
For epoch number: 56, train loss: 1.124009379065863 and accuracy: 70.82347278488629
For epoch: 56, test loss: 1.1363895233673384 and accuracy: 71.16
For epoch number: 57, train loss: 1.1139081975688105 and accuracy: 71.41692029201727
For epoch: 57, test loss: 1.1371054347557357 and accuracy: 71.23
For epoch number: 58, train loss: 1.1274135208555631 and accuracy: 71.02314861208538
For epoch: 58, test loss: 1.1379733659044098 and accuracy: 71.17
For epoch number: 59, train loss: 1.1179983170621424 and accuracy: 71.41275242102721
For epoch: 59, test loss: 1.1378870146184028 and accuracy: 71.3
For epoch number: 60, train loss: 1.1106874051065785 and accuracy: 71.70100832967996
For epoch: 60, test loss: 1.1357618396795248 and accuracy: 71.45
For epoch number: 61, train loss: 1.110834154291134 and accuracy: 71.77720644357852
For epoch: 61, test loss: 1.1340204288687887 and accuracy: 71.51
For epoch number: 62, train loss: 1.097040838403664 and accuracy: 72.0717306311338
For epoch: 62, test loss: 1.132349868363972 and accuracy: 71.63
For epoch number: 63, train loss: 1.11506504918089 and accuracy: 71.70557341693791
For epoch: 63, test loss: 1.1322342164908783 and accuracy: 71.69
For epoch number: 64, train loss: 1.106844145944803 and accuracy: 71.85748199573085
For epoch: 64, test loss: 1.1317222842687293 and accuracy: 71.8
For epoch number: 65, train loss: 1.1292979303695572 and accuracy: 71.75411873171123
For epoch: 65, test loss: 1.1304716814922382 and accuracy: 71.89
For epoch number: 66, train loss: 1.1064692647325192 and accuracy: 72.12018366939509
For epoch: 66, test loss: 1.1292618196221846 and accuracy: 71.96
For epoch number: 67, train loss: 1.1099879554441388 and accuracy: 72.24039329788302
For epoch: 67, test loss: 1.1293143139609807 and accuracy: 71.94
For epoch number: 68, train loss: 1.1144375861281215 and accuracy: 71.93507563126494
For epoch: 68, test loss: 1.1295350940921638 and accuracy: 72.05
For epoch number: 69, train loss: 1.1154537994672757 and accuracy: 72.3273953200742
For epoch: 69, test loss: 1.1300526857376099 and accuracy: 72.1
For epoch number: 70, train loss: 1.1030158584296939 and accuracy: 72.39323736991108
For epoch: 70, test loss: 1.130748632587964 and accuracy: 72.15
For epoch number: 71, train loss: 1.0881140904398414 and accuracy: 72.73305253119288
For epoch: 71, test loss: 1.130924304829368 and accuracy: 72.21
For epoch number: 72, train loss: 1.1159726643397403 and accuracy: 72.43621611947422
For epoch: 72, test loss: 1.1309746186944503 and accuracy: 72.3
For epoch number: 73, train loss: 1.1251057410989622 and accuracy: 72.06528437667734
For epoch: 73, test loss: 1.1313130787656278 and accuracy: 72.36
For epoch number: 74, train loss: 1.1046114638006899 and accuracy: 72.69574230585233
For epoch: 74, test loss: 1.1305600118033494 and accuracy: 72.43
For epoch number: 75, train loss: 1.0976809636349716 and accuracy: 72.76078289961336
For epoch: 75, test loss: 1.128661728357967 and accuracy: 72.51
For epoch number: 76, train loss: 1.0951575472151072 and accuracy: 72.79513853954967
For epoch: 76, test loss: 1.1276553854157654 and accuracy: 72.53
For epoch number: 77, train loss: 1.1110976858744546 and accuracy: 72.4853848001922
For epoch: 77, test loss: 1.1270196264303183 and accuracy: 72.57
For epoch number: 78, train loss: 1.0886494510230564 and accuracy: 72.78672738580055
For epoch: 78, test loss: 1.1267194355590433 and accuracy: 72.64
For epoch number: 79, train loss: 1.1073999358784585 and accuracy: 72.84858442365105
For epoch: 79, test loss: 1.1263583483575266 and accuracy: 72.64
For epoch number: 80, train loss: 1.092111842604134 and accuracy: 73.16582714476277
For epoch: 80, test loss: 1.1259289746043049 and accuracy: 72.66
For epoch number: 81, train loss: 1.0958170708320725 and accuracy: 73.01070732638262
For epoch: 81, test loss: 1.1255703658997258 and accuracy: 72.67
For epoch number: 82, train loss: 1.1061792431721393 and accuracy: 72.73657186409403
For epoch: 82, test loss: 1.1253914470914044 and accuracy: 72.72
For epoch number: 83, train loss: 1.1053244219106786 and accuracy: 72.91621176330469
For epoch: 83, test loss: 1.1251860117610497 and accuracy: 72.73
For epoch number: 84, train loss: 1.1065509650181597 and accuracy: 72.95450924155513
For epoch: 84, test loss: 1.1247514780563643 and accuracy: 72.77
For epoch number: 85, train loss: 1.1195336116684809 and accuracy: 72.54945187085396
For epoch: 85, test loss: 1.1243485031248648 and accuracy: 72.76
For epoch number: 86, train loss: 1.1010191077052958 and accuracy: 72.88142371525694
For epoch: 86, test loss: 1.1241646205322653 and accuracy: 72.75
For epoch number: 87, train loss: 1.1049639765445063 and accuracy: 72.81491387397458
For epoch: 87, test loss: 1.1237825532502765 and accuracy: 72.74
For epoch number: 88, train loss: 1.1053901330637839 and accuracy: 72.99450823764353
For epoch: 88, test loss: 1.123445438433297 and accuracy: 72.77
For epoch number: 89, train loss: 1.1078898714358114 and accuracy: 72.6695723783317
For epoch: 89, test loss: 1.123490264144125 and accuracy: 72.79
For epoch number: 90, train loss: 1.1071580006616322 and accuracy: 72.8612337429901
For epoch: 90, test loss: 1.123646911940997 and accuracy: 72.79
For epoch number: 91, train loss: 1.0972046609893737 and accuracy: 73.23994541221803
For epoch: 91, test loss: 1.123800831505015 and accuracy: 72.82
For epoch number: 92, train loss: 1.1095829970765823 and accuracy: 72.71836310178611
For epoch: 92, test loss: 1.123819134657896 and accuracy: 72.82
For epoch number: 93, train loss: 1.1062856415710827 and accuracy: 72.7447293675241
For epoch: 93, test loss: 1.12378190137163 and accuracy: 72.82
For epoch number: 94, train loss: 1.0932950559589598 and accuracy: 73.13699510158195
For epoch: 94, test loss: 1.123760916009734 and accuracy: 72.84
For epoch number: 95, train loss: 1.0840376735913873 and accuracy: 73.43440606436386
For epoch: 95, test loss: 1.1237364856502678 and accuracy: 72.84
For epoch number: 96, train loss: 1.1075988383520217 and accuracy: 73.16012980249188
For epoch: 96, test loss: 1.1237218432788607 and accuracy: 72.84
For epoch number: 97, train loss: 1.096997114642714 and accuracy: 73.16907323707052
For epoch: 97, test loss: 1.1237110865267017 and accuracy: 72.84
For epoch number: 98, train loss: 1.1037961688673072 and accuracy: 73.00428756605844
For epoch: 98, test loss: 1.1237034367609628 and accuracy: 72.84
For epoch number: 99, train loss: 1.0937855740976052 and accuracy: 72.95452725962693
For epoch: 99, test loss: 1.1237025102482567 and accuracy: 72.84
Test accuracy: 72.84
