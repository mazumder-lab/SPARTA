Namespace(dataset='cifar10', batch_size=5000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=100, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=True, magnitude_descending=False, type_mask='magnitude', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=1.0, experiment_dir='benchmarking_all_exp_gc_2', out_file='benchmarking_all_exp_gc_2/0_0_smallest_adaptive_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_2/0_0_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=0, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=12.03125 and C=1.0
For epoch number: 0, train loss: 2.2448964904225064 and accuracy: 16.65697499548836
For epoch: 0, test loss: 1.9976251004617425 and accuracy: 38.45
For epoch number: 1, train loss: 1.8176778922261112 and accuracy: 46.895720313441835
For epoch: 1, test loss: 1.6467141169535964 and accuracy: 52.14
For epoch number: 2, train loss: 1.5831130420266404 and accuracy: 52.534562211981566
For epoch: 2, test loss: 1.5045111043543755 and accuracy: 54.32
For epoch number: 3, train loss: 1.468966905291625 and accuracy: 53.98658199120065
For epoch: 3, test loss: 1.4167006181765207 and accuracy: 55.5
For epoch number: 4, train loss: 1.3931757307897403 and accuracy: 55.16151475996422
For epoch: 4, test loss: 1.3641827951503704 and accuracy: 56.03
For epoch number: 5, train loss: 1.353145358826332 and accuracy: 55.37489788192161
For epoch: 5, test loss: 1.3397852951967264 and accuracy: 56.55
For epoch number: 6, train loss: 1.333011444518983 and accuracy: 56.09814197236779
For epoch: 6, test loss: 1.3205239863335332 and accuracy: 56.85
For epoch number: 7, train loss: 1.307703912140585 and accuracy: 56.89122065072114
For epoch: 7, test loss: 1.2981072588811946 and accuracy: 57.35
For epoch number: 8, train loss: 1.300491968593975 and accuracy: 56.884442221110554
For epoch: 8, test loss: 1.2832622663884223 and accuracy: 57.72
For epoch number: 9, train loss: 1.2735157743155718 and accuracy: 57.60501491574619
For epoch: 9, test loss: 1.2663549199888977 and accuracy: 58.11
For epoch number: 10, train loss: 1.2673743785017788 and accuracy: 57.944224382827194
For epoch: 10, test loss: 1.2584954545467715 and accuracy: 58.42
For epoch number: 11, train loss: 1.2540590501730404 and accuracy: 58.438776327380474
For epoch: 11, test loss: 1.2547789600831043 and accuracy: 58.85
For epoch number: 12, train loss: 1.245386109200434 and accuracy: 59.03713671694551
For epoch: 12, test loss: 1.2498913309242152 and accuracy: 58.9
For epoch number: 13, train loss: 1.2464969979496452 and accuracy: 59.079960984931425
For epoch: 13, test loss: 1.2515025546279135 and accuracy: 59.13
For epoch number: 14, train loss: 1.2431676907843328 and accuracy: 59.21131969288901
For epoch: 14, test loss: 1.245435971247999 and accuracy: 59.82
For epoch number: 15, train loss: 1.2479575698574383 and accuracy: 59.685023573076535
For epoch: 15, test loss: 1.2429318586482276 and accuracy: 59.97
For epoch number: 16, train loss: 1.2455978766670377 and accuracy: 59.787153926950594
For epoch: 16, test loss: 1.2449955200847191 and accuracy: 60.2
For epoch number: 17, train loss: 1.247340270165626 and accuracy: 60.078562740523616
For epoch: 17, test loss: 1.245865121672425 and accuracy: 60.57
For epoch number: 18, train loss: 1.229923892234053 and accuracy: 60.77987622919629
For epoch: 18, test loss: 1.2482777992381324 and accuracy: 60.6
For epoch number: 19, train loss: 1.2582743841668833 and accuracy: 60.268633447262694
For epoch: 19, test loss: 1.245495388779459 and accuracy: 61.09
For epoch number: 20, train loss: 1.2409208836640127 and accuracy: 61.06131086665735
For epoch: 20, test loss: 1.2450272727616225 and accuracy: 61.43
For epoch number: 21, train loss: 1.2344160895846064 and accuracy: 61.34298014828988
For epoch: 21, test loss: 1.2461184693288199 and accuracy: 61.77
For epoch number: 22, train loss: 1.2389562277204962 and accuracy: 61.56011824562109
For epoch: 22, test loss: 1.243524596660952 and accuracy: 62.05
For epoch number: 23, train loss: 1.241527939640631 and accuracy: 61.93453329085696
For epoch: 23, test loss: 1.2409567772587644 and accuracy: 62.21
For epoch number: 24, train loss: 1.2433518665650534 and accuracy: 62.050572499949865
For epoch: 24, test loss: 1.2387245908568176 and accuracy: 62.23
For epoch number: 25, train loss: 1.2320632546254904 and accuracy: 62.53774622537746
For epoch: 25, test loss: 1.2390579068208043 and accuracy: 62.53
For epoch number: 26, train loss: 1.2280524642160624 and accuracy: 63.001741706872735
For epoch: 26, test loss: 1.2378041940399362 and accuracy: 62.7
For epoch number: 27, train loss: 1.2173950860561955 and accuracy: 63.19749593691687
For epoch: 27, test loss: 1.2353514470631564 and accuracy: 63.15
For epoch number: 28, train loss: 1.2271933986081018 and accuracy: 63.398666639972774
For epoch: 28, test loss: 1.2354423358470579 and accuracy: 63.35
For epoch number: 29, train loss: 1.2256751596456459 and accuracy: 63.614718181636285
For epoch: 29, test loss: 1.2385167856759662 and accuracy: 63.56
For epoch number: 30, train loss: 1.2160793999634167 and accuracy: 64.0364552104569
For epoch: 30, test loss: 1.236294120172911 and accuracy: 63.91
For epoch number: 31, train loss: 1.2349629157628768 and accuracy: 63.670673748951636
For epoch: 31, test loss: 1.2386189819891242 and accuracy: 64.11
For epoch number: 32, train loss: 1.2257499009253008 and accuracy: 64.26741393114492
For epoch: 32, test loss: 1.2377683060078681 and accuracy: 64.42
For epoch number: 33, train loss: 1.232199309834429 and accuracy: 64.48459299407808
For epoch: 33, test loss: 1.234469681600981 and accuracy: 64.72
For epoch number: 34, train loss: 1.2336256251154667 and accuracy: 64.24585491187923
For epoch: 34, test loss: 1.2332214833814887 and accuracy: 64.93
For epoch number: 35, train loss: 1.2401312360943668 and accuracy: 64.50764722411786
For epoch: 35, test loss: 1.2302794464026825 and accuracy: 65.03
For epoch number: 36, train loss: 1.2211697165455138 and accuracy: 64.8927055729343
For epoch: 36, test loss: 1.2243488762952104 and accuracy: 65.21
For epoch number: 37, train loss: 1.217986722747643 and accuracy: 65.36688475088073
For epoch: 37, test loss: 1.2226580645464644 and accuracy: 65.41
For epoch number: 38, train loss: 1.2257519753491855 and accuracy: 65.31698564593302
For epoch: 38, test loss: 1.2217881121212923 and accuracy: 65.52
For epoch number: 39, train loss: 1.204377597404851 and accuracy: 65.8193791912621
For epoch: 39, test loss: 1.2221107256563404 and accuracy: 65.67
For epoch number: 40, train loss: 1.2247735377129247 and accuracy: 65.40284360189574
For epoch: 40, test loss: 1.2214714371705357 and accuracy: 65.8
For epoch number: 41, train loss: 1.2249241851240515 and accuracy: 65.63208020050125
For epoch: 41, test loss: 1.2169810390170617 and accuracy: 66.04
For epoch number: 42, train loss: 1.2197805698445663 and accuracy: 65.84294782226836
For epoch: 42, test loss: 1.210353049296367 and accuracy: 66.19
For epoch number: 43, train loss: 1.2058302821989306 and accuracy: 66.13611637184188
For epoch: 43, test loss: 1.2072019954270954 and accuracy: 66.41
For epoch number: 44, train loss: 1.2059400908752653 and accuracy: 66.06696151614001
For epoch: 44, test loss: 1.2040501138831996 and accuracy: 66.53
For epoch number: 45, train loss: 1.1749865682464344 and accuracy: 67.24155139030282
For epoch: 45, test loss: 1.204111307482176 and accuracy: 66.69
For epoch number: 46, train loss: 1.1901383945156658 and accuracy: 66.70883026141429
For epoch: 46, test loss: 1.2049543653862387 and accuracy: 66.82
For epoch number: 47, train loss: 1.2017190956453205 and accuracy: 66.58902899365513
For epoch: 47, test loss: 1.204519648340684 and accuracy: 66.86
For epoch number: 48, train loss: 1.197503238798134 and accuracy: 67.03655483224837
For epoch: 48, test loss: 1.2037453145920476 and accuracy: 66.93
For epoch number: 49, train loss: 1.1843280776862115 and accuracy: 67.19996800191988
For epoch: 49, test loss: 1.200725690473484 and accuracy: 67.14
For epoch number: 50, train loss: 1.190620288787135 and accuracy: 67.18375887809098
For epoch: 50, test loss: 1.1994706075402755 and accuracy: 67.27
For epoch number: 51, train loss: 1.1734000426672755 and accuracy: 67.39950252748135
For epoch: 51, test loss: 1.1972231472594828 and accuracy: 67.35
For epoch number: 52, train loss: 1.1777453560998121 and accuracy: 67.46916155175496
For epoch: 52, test loss: 1.1963945076435427 and accuracy: 67.48
For epoch number: 53, train loss: 1.1838596576736087 and accuracy: 67.72266943651
For epoch: 53, test loss: 1.196679408791699 and accuracy: 67.52
For epoch number: 54, train loss: 1.1853542398558303 and accuracy: 67.49390560684171
For epoch: 54, test loss: 1.1943161774285231 and accuracy: 67.69
For epoch number: 55, train loss: 1.1904682712979835 and accuracy: 67.74019323478225
For epoch: 55, test loss: 1.192085009586962 and accuracy: 67.77
For epoch number: 56, train loss: 1.188589378691754 and accuracy: 67.63650141586567
For epoch: 56, test loss: 1.1916413073298298 and accuracy: 67.9
For epoch number: 57, train loss: 1.1633399918145342 and accuracy: 68.28865075887344
For epoch: 57, test loss: 1.1922837209097947 and accuracy: 68.01
For epoch number: 58, train loss: 1.1855537392535707 and accuracy: 67.94449297228618
For epoch: 58, test loss: 1.1930189072331296 and accuracy: 68.01
For epoch number: 59, train loss: 1.1768917818069458 and accuracy: 68.15150167751324
For epoch: 59, test loss: 1.193197631383244 and accuracy: 68.08
For epoch number: 60, train loss: 1.169293445171696 and accuracy: 68.55014280863642
For epoch: 60, test loss: 1.191861088517346 and accuracy: 68.11
For epoch number: 61, train loss: 1.171678614686932 and accuracy: 68.4165403939708
For epoch: 61, test loss: 1.1898536644404447 and accuracy: 68.21
For epoch number: 62, train loss: 1.173942250308424 and accuracy: 68.57251343951718
For epoch: 62, test loss: 1.1878887331938441 and accuracy: 68.29
For epoch number: 63, train loss: 1.166131869779797 and accuracy: 68.64167031916165
For epoch: 63, test loss: 1.1868288034125218 and accuracy: 68.41
For epoch number: 64, train loss: 1.1846838203579069 and accuracy: 68.5869000519522
For epoch: 64, test loss: 1.1856977471822425 and accuracy: 68.51
For epoch number: 65, train loss: 1.172476318985106 and accuracy: 68.63711657053905
For epoch: 65, test loss: 1.1838770176790938 and accuracy: 68.61
For epoch number: 66, train loss: 1.1811683733864586 and accuracy: 68.46052051168945
For epoch: 66, test loss: 1.1826005230976055 and accuracy: 68.7
For epoch number: 67, train loss: 1.170926862835884 and accuracy: 68.75012573175884
For epoch: 67, test loss: 1.1830143332481384 and accuracy: 68.73
For epoch number: 68, train loss: 1.1848473301318687 and accuracy: 68.7238868329951
For epoch: 68, test loss: 1.1832801186585729 and accuracy: 68.78
For epoch number: 69, train loss: 1.1751175618979086 and accuracy: 68.79713613418338
For epoch: 69, test loss: 1.183232221422316 and accuracy: 68.92
For epoch number: 70, train loss: 1.163074828273668 and accuracy: 69.12344675875464
For epoch: 70, test loss: 1.1839217551146881 and accuracy: 69.01
For epoch number: 71, train loss: 1.1661954276425364 and accuracy: 69.35136858042154
For epoch: 71, test loss: 1.183746394477313 and accuracy: 69.04
For epoch number: 72, train loss: 1.1652801007385782 and accuracy: 69.15171711931036
For epoch: 72, test loss: 1.1833071044728727 and accuracy: 69.03
For epoch number: 73, train loss: 1.164010788102549 and accuracy: 69.4095918736073
For epoch: 73, test loss: 1.1832795128037659 and accuracy: 69.04
For epoch number: 74, train loss: 1.1654849395214804 and accuracy: 69.37821971965975
For epoch: 74, test loss: 1.1820885380612145 and accuracy: 69.09
For epoch number: 75, train loss: 1.1656146439851498 and accuracy: 69.16126731260773
For epoch: 75, test loss: 1.1800956016854396 and accuracy: 69.13
For epoch number: 76, train loss: 1.1678165897844344 and accuracy: 69.26716768062349
For epoch: 76, test loss: 1.1786870692349687 and accuracy: 69.13
For epoch number: 77, train loss: 1.157861612648832 and accuracy: 69.5016651045925
For epoch: 77, test loss: 1.1779303120661386 and accuracy: 69.22
For epoch number: 78, train loss: 1.1738006226394488 and accuracy: 69.36954876737425
For epoch: 78, test loss: 1.1779980138887334 and accuracy: 69.23
For epoch number: 79, train loss: 1.1718561253519564 and accuracy: 69.41549253671855
For epoch: 79, test loss: 1.1777694942075996 and accuracy: 69.31
For epoch number: 80, train loss: 1.1691754989633392 and accuracy: 69.28536029338883
For epoch: 80, test loss: 1.1770870904379254 and accuracy: 69.33
For epoch number: 81, train loss: 1.162355025411837 and accuracy: 69.27192276749798
For epoch: 81, test loss: 1.1764063495623915 and accuracy: 69.37
For epoch number: 82, train loss: 1.1543543255140658 and accuracy: 69.63932065054313
For epoch: 82, test loss: 1.1758099137982236 and accuracy: 69.4
For epoch number: 83, train loss: 1.1703238353340573 and accuracy: 69.27769054233603
For epoch: 83, test loss: 1.1755512122866474 and accuracy: 69.43
For epoch number: 84, train loss: 1.1689801066228658 and accuracy: 69.5194563060083
For epoch: 84, test loss: 1.1751082630097112 and accuracy: 69.44
For epoch number: 85, train loss: 1.1565489241257016 and accuracy: 69.76232834269494
For epoch: 85, test loss: 1.174701689919339 and accuracy: 69.45
For epoch number: 86, train loss: 1.169629501656557 and accuracy: 69.6216736133376
For epoch: 86, test loss: 1.1744047856029076 and accuracy: 69.47
For epoch number: 87, train loss: 1.1644184902783423 and accuracy: 69.65812821693937
For epoch: 87, test loss: 1.1739088485512552 and accuracy: 69.5
For epoch number: 88, train loss: 1.1514490466616327 and accuracy: 69.79131370712165
For epoch: 88, test loss: 1.173550554468662 and accuracy: 69.54
For epoch number: 89, train loss: 1.1466876381470752 and accuracy: 69.85811350919265
For epoch: 89, test loss: 1.1735622128353844 and accuracy: 69.55
For epoch number: 90, train loss: 1.1584599211664484 and accuracy: 69.62628040973111
For epoch: 90, test loss: 1.173564781116534 and accuracy: 69.55
For epoch number: 91, train loss: 1.1602158371139975 and accuracy: 69.75550560009549
For epoch: 91, test loss: 1.1736239413671856 and accuracy: 69.54
For epoch number: 92, train loss: 1.1543345721107228 and accuracy: 69.85258772632591
For epoch: 92, test loss: 1.1736222324492056 and accuracy: 69.54
For epoch number: 93, train loss: 1.1678045388523395 and accuracy: 69.60531022695656
For epoch: 93, test loss: 1.1735710584664647 and accuracy: 69.54
For epoch number: 94, train loss: 1.1744191768629177 and accuracy: 69.30786345687426
For epoch: 94, test loss: 1.17356090983258 and accuracy: 69.53
For epoch number: 95, train loss: 1.1611226099552494 and accuracy: 69.58190870373703
For epoch: 95, test loss: 1.1735301591173004 and accuracy: 69.54
For epoch number: 96, train loss: 1.149675765604076 and accuracy: 69.85795057239326
For epoch: 96, test loss: 1.17350769722009 and accuracy: 69.54
For epoch number: 97, train loss: 1.1496351214336828 and accuracy: 69.73671038141956
For epoch: 97, test loss: 1.173492025725449 and accuracy: 69.54
For epoch number: 98, train loss: 1.1603502414231197 and accuracy: 69.48257446892677
For epoch: 98, test loss: 1.1734826481795009 and accuracy: 69.54
For epoch number: 99, train loss: 1.147678777516595 and accuracy: 69.84574191743596
For epoch: 99, test loss: 1.1734817850438855 and accuracy: 69.54
Test accuracy: 69.54
