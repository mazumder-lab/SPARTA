Namespace(dataset='cifar10', batch_size=5000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=100, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=True, magnitude_descending=True, type_mask='magnitude', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=1.0, experiment_dir='benchmarking_all_exp_gc_2', out_file='benchmarking_all_exp_gc_2/0_0_largest_adaptive_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_2/0_0_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=0, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=12.03125 and C=1.0
For epoch number: 0, train loss: 2.2389980334611166 and accuracy: 17.328708066812375
For epoch: 0, test loss: 1.9748984695989875 and accuracy: 40.69
For epoch number: 1, train loss: 1.7904927367955505 and accuracy: 47.90436005625879
For epoch: 1, test loss: 1.6189448561849473 and accuracy: 52.77
For epoch number: 2, train loss: 1.5561118012831616 and accuracy: 52.877690665709096
For epoch: 2, test loss: 1.4787328756308253 and accuracy: 54.47
For epoch number: 3, train loss: 1.4466810275719861 and accuracy: 54.11996575819713
For epoch: 3, test loss: 1.399901171273823 and accuracy: 55.37
For epoch number: 4, train loss: 1.3800548385447404 and accuracy: 55.07206043136865
For epoch: 4, test loss: 1.3558315612092804 and accuracy: 55.93
For epoch number: 5, train loss: 1.3472424606560718 and accuracy: 55.26730029688963
For epoch: 5, test loss: 1.3366318428063695 and accuracy: 56.42
For epoch number: 6, train loss: 1.3316425328638792 and accuracy: 55.72693346037796
For epoch: 6, test loss: 1.320109915129746 and accuracy: 56.7
For epoch number: 7, train loss: 1.308406526990661 and accuracy: 56.55209559336911
For epoch: 7, test loss: 1.298594130745417 and accuracy: 57.05
For epoch number: 8, train loss: 1.301467493383011 and accuracy: 56.49824912456228
For epoch: 8, test loss: 1.2864647469943082 and accuracy: 57.37
For epoch number: 9, train loss: 1.2798988255134143 and accuracy: 57.074901233572525
For epoch: 9, test loss: 1.2737154915362974 and accuracy: 57.8
For epoch number: 10, train loss: 1.2764789268521979 and accuracy: 57.40207258032249
For epoch: 10, test loss: 1.2682927816729002 and accuracy: 58.04
For epoch number: 11, train loss: 1.2652853182147419 and accuracy: 57.633939296868746
For epoch: 11, test loss: 1.2658033989652802 and accuracy: 58.26
For epoch number: 12, train loss: 1.2578899382833932 and accuracy: 58.17550061258511
For epoch: 12, test loss: 1.2616042849383777 and accuracy: 58.39
For epoch number: 13, train loss: 1.2607551271051873 and accuracy: 58.3275275195573
For epoch: 13, test loss: 1.2624523986743976 and accuracy: 58.67
For epoch number: 14, train loss: 1.2555918593805624 and accuracy: 58.35510712706516
For epoch: 14, test loss: 1.2556252615361274 and accuracy: 58.89
For epoch number: 15, train loss: 1.2587285524322873 and accuracy: 58.894573176848226
For epoch: 15, test loss: 1.253261901909792 and accuracy: 59.11
For epoch number: 16, train loss: 1.2568048774961411 and accuracy: 58.893358964704014
For epoch: 16, test loss: 1.255639762818059 and accuracy: 59.39
For epoch number: 17, train loss: 1.2568502802350348 and accuracy: 59.26302566249925
For epoch: 17, test loss: 1.255593232716186 and accuracy: 59.7
For epoch number: 18, train loss: 1.2419176556997829 and accuracy: 59.82856341751617
For epoch: 18, test loss: 1.2564782854876941 and accuracy: 59.77
For epoch number: 19, train loss: 1.2676424766953283 and accuracy: 59.2712518238692
For epoch: 19, test loss: 1.253358954115759 and accuracy: 60.1
For epoch number: 20, train loss: 1.2500016799810134 and accuracy: 60.06508415021262
For epoch: 20, test loss: 1.252376191223724 and accuracy: 60.42
For epoch number: 21, train loss: 1.2442725407771575 and accuracy: 60.18496372478673
For epoch: 21, test loss: 1.2535150458541098 and accuracy: 60.59
For epoch number: 22, train loss: 1.2502532644100872 and accuracy: 60.393749874313755
For epoch: 22, test loss: 1.2504157514511784 and accuracy: 60.97
For epoch number: 23, train loss: 1.2513329532202773 and accuracy: 60.717983434214716
For epoch: 23, test loss: 1.2469106007225905 and accuracy: 60.93
For epoch number: 24, train loss: 1.2502763109311226 and accuracy: 60.81734143455854
For epoch: 24, test loss: 1.2445626854896545 and accuracy: 61.19
For epoch number: 25, train loss: 1.2388742112877345 and accuracy: 61.24987501249875
For epoch: 25, test loss: 1.2448388496531715 and accuracy: 61.28
For epoch number: 26, train loss: 1.2363746129640258 and accuracy: 61.60837620868451
For epoch: 26, test loss: 1.2436896947365772 and accuracy: 61.43
For epoch number: 27, train loss: 1.2274547321184965 and accuracy: 61.71472140291739
For epoch: 27, test loss: 1.2415985080260266 and accuracy: 61.74
For epoch number: 28, train loss: 1.2362263228685137 and accuracy: 61.973212676930466
For epoch: 28, test loss: 1.2424798736089393 and accuracy: 61.9
For epoch number: 29, train loss: 1.2358735699663048 and accuracy: 62.02605094139538
For epoch: 29, test loss: 1.2472621813605103 and accuracy: 62.15
For epoch number: 30, train loss: 1.2270236173478684 and accuracy: 62.43754247111964
For epoch: 30, test loss: 1.2472237129754657 and accuracy: 62.25
For epoch number: 31, train loss: 1.2481114135456273 and accuracy: 62.05519389751987
For epoch: 31, test loss: 1.249775088286098 and accuracy: 62.48
For epoch number: 32, train loss: 1.23977075782218 and accuracy: 62.4519615692554
For epoch: 32, test loss: 1.2480835039404374 and accuracy: 62.52
For epoch number: 33, train loss: 1.2419767416495215 and accuracy: 62.936866405701096
For epoch: 33, test loss: 1.2441766020617908 and accuracy: 62.88
For epoch number: 34, train loss: 1.2452079043445359 and accuracy: 62.53562969207917
For epoch: 34, test loss: 1.2425409970404226 and accuracy: 63.01
For epoch number: 35, train loss: 1.24988064709051 and accuracy: 62.813616474649756
For epoch: 35, test loss: 1.2388643147070197 and accuracy: 63.14
For epoch number: 36, train loss: 1.2318293383670231 and accuracy: 63.21106218494092
For epoch: 36, test loss: 1.2344217858737028 and accuracy: 63.28
For epoch number: 37, train loss: 1.2326756858255759 and accuracy: 63.34977352793155
For epoch: 37, test loss: 1.2335616697238971 and accuracy: 63.44
For epoch number: 38, train loss: 1.2368557494302708 and accuracy: 63.48684210526316
For epoch: 38, test loss: 1.2318427585348297 and accuracy: 63.63
For epoch number: 39, train loss: 1.2178460888209797 and accuracy: 63.88989278400193
For epoch: 39, test loss: 1.2317961167685594 and accuracy: 63.7
For epoch number: 40, train loss: 1.2390260956226251 and accuracy: 63.5807877653431
For epoch: 40, test loss: 1.231631494775603 and accuracy: 63.79
For epoch number: 41, train loss: 1.2386994588660054 and accuracy: 63.61704260651629
For epoch: 41, test loss: 1.2274901783919032 and accuracy: 64.19
For epoch number: 42, train loss: 1.2312470930131527 and accuracy: 63.94866062517466
For epoch: 42, test loss: 1.2213753137407424 and accuracy: 64.33
For epoch number: 43, train loss: 1.2171786873640416 and accuracy: 64.38932989483015
For epoch: 43, test loss: 1.2181086102618446 and accuracy: 64.55
For epoch number: 44, train loss: 1.222819131245433 and accuracy: 64.18179271148112
For epoch: 44, test loss: 1.2152084263065193 and accuracy: 64.7
For epoch number: 45, train loss: 1.192377605810467 and accuracy: 65.15559813960915
For epoch: 45, test loss: 1.2148673904093006 and accuracy: 64.9
For epoch number: 46, train loss: 1.203957457036253 and accuracy: 64.74721921053688
For epoch: 46, test loss: 1.2156431486334982 and accuracy: 65.0
For epoch number: 47, train loss: 1.2146225120153864 and accuracy: 64.65143361978957
For epoch: 47, test loss: 1.2153688948365706 and accuracy: 65.06
For epoch number: 48, train loss: 1.213216945410721 and accuracy: 64.98347521281923
For epoch: 48, test loss: 1.2149394554427908 and accuracy: 65.09
For epoch number: 49, train loss: 1.2001419469477639 and accuracy: 65.37607743535388
For epoch: 49, test loss: 1.211953718451005 and accuracy: 65.22
For epoch number: 50, train loss: 1.204071670058239 and accuracy: 65.20593147019174
For epoch: 50, test loss: 1.2109557412847687 and accuracy: 65.32
For epoch number: 51, train loss: 1.1866136334008641 and accuracy: 65.45775495466582
For epoch: 51, test loss: 1.2089632892910438 and accuracy: 65.46
For epoch number: 52, train loss: 1.1931792637259941 and accuracy: 65.57614762727688
For epoch: 52, test loss: 1.2084494127502925 and accuracy: 65.63
For epoch number: 53, train loss: 1.1992536821062603 and accuracy: 65.74316361384655
For epoch: 53, test loss: 1.2088992029805727 and accuracy: 65.71
For epoch number: 54, train loss: 1.2006387899044475 and accuracy: 65.50373656236263
For epoch: 54, test loss: 1.2066473659080794 and accuracy: 65.8
For epoch number: 55, train loss: 1.20290475788683 and accuracy: 65.60980976575783
For epoch: 55, test loss: 1.2045373184771477 and accuracy: 65.75
For epoch number: 56, train loss: 1.2039458645871406 and accuracy: 65.59246998763611
For epoch: 56, test loss: 1.20422795528098 and accuracy: 65.92
For epoch number: 57, train loss: 1.1790569060640372 and accuracy: 66.29884874317811
For epoch: 57, test loss: 1.2049946452997908 and accuracy: 65.87
For epoch number: 58, train loss: 1.2003029718380311 and accuracy: 65.81632653061224
For epoch: 58, test loss: 1.2056958350954177 and accuracy: 65.95
For epoch number: 59, train loss: 1.1946298213005067 and accuracy: 66.19103439912689
For epoch: 59, test loss: 1.20551000441177 and accuracy: 66.15
For epoch number: 60, train loss: 1.18388458218905 and accuracy: 66.4849102203048
For epoch: 60, test loss: 1.2050605212585837 and accuracy: 66.21
For epoch number: 61, train loss: 1.1922690045433872 and accuracy: 66.02201132466703
For epoch: 61, test loss: 1.2038794401325756 and accuracy: 66.3
For epoch number: 62, train loss: 1.192708174544986 and accuracy: 66.5181158696217
For epoch: 62, test loss: 1.2022501652753805 and accuracy: 66.38
For epoch number: 63, train loss: 1.1823108355830034 and accuracy: 66.47806510738336
For epoch: 63, test loss: 1.2012719700608072 and accuracy: 66.48
For epoch number: 64, train loss: 1.198254794824736 and accuracy: 66.42688726371738
For epoch: 64, test loss: 1.199814407885829 and accuracy: 66.57
For epoch number: 65, train loss: 1.1902550701567307 and accuracy: 66.51565649510049
For epoch: 65, test loss: 1.1978962255429617 and accuracy: 66.64
For epoch number: 66, train loss: 1.1964727666118358 and accuracy: 66.32112924569917
For epoch: 66, test loss: 1.1966371815415877 and accuracy: 66.74
For epoch number: 67, train loss: 1.1843918186426163 and accuracy: 66.76859321249673
For epoch: 67, test loss: 1.1972812565067146 and accuracy: 66.85
For epoch number: 68, train loss: 1.1967682680041771 and accuracy: 66.7084477338745
For epoch: 68, test loss: 1.1979451564293873 and accuracy: 66.9
For epoch number: 69, train loss: 1.1936512680880103 and accuracy: 66.64923677171531
For epoch: 69, test loss: 1.1980027775221234 and accuracy: 66.99
For epoch number: 70, train loss: 1.1778971449596676 and accuracy: 67.04651301056303
For epoch: 70, test loss: 1.1985090978537933 and accuracy: 67.03
For epoch number: 71, train loss: 1.1831479005559662 and accuracy: 67.26363600143432
For epoch: 71, test loss: 1.1979180438609063 and accuracy: 67.04
For epoch number: 72, train loss: 1.1800212891912272 and accuracy: 67.07441182926586
For epoch: 72, test loss: 1.1971901202503639 and accuracy: 67.07
For epoch number: 73, train loss: 1.180245395200661 and accuracy: 67.27360327625318
For epoch: 73, test loss: 1.1972911569136608 and accuracy: 67.17
For epoch number: 74, train loss: 1.182365936017319 and accuracy: 67.16385128389442
For epoch: 74, test loss: 1.1961562542975703 and accuracy: 67.23
For epoch number: 75, train loss: 1.1806207303907357 and accuracy: 67.07483801937823
For epoch: 75, test loss: 1.1939927294284483 and accuracy: 67.25
For epoch number: 76, train loss: 1.1864155205919986 and accuracy: 67.26112370273172
For epoch: 76, test loss: 1.192617892464505 and accuracy: 67.21
For epoch number: 77, train loss: 1.1792270395124382 and accuracy: 67.1605479889126
For epoch: 77, test loss: 1.1920934198777886 and accuracy: 67.24
For epoch number: 78, train loss: 1.1903830112911495 and accuracy: 67.16117726711538
For epoch: 78, test loss: 1.192410176313376 and accuracy: 67.22
For epoch number: 79, train loss: 1.1897355809895604 and accuracy: 67.25721915542358
For epoch: 79, test loss: 1.1922895259495023 and accuracy: 67.26
For epoch number: 80, train loss: 1.1851991499336858 and accuracy: 67.10476756863912
For epoch: 80, test loss: 1.191556359393687 and accuracy: 67.34
For epoch number: 81, train loss: 1.1768594560755887 and accuracy: 67.22244569589702
For epoch: 81, test loss: 1.1907945773269557 and accuracy: 67.37
For epoch number: 82, train loss: 1.16979991918496 and accuracy: 67.50285062713797
For epoch: 82, test loss: 1.1902128684369824 and accuracy: 67.37
For epoch number: 83, train loss: 1.186889288676662 and accuracy: 67.14377742883602
For epoch: 83, test loss: 1.1900618378120134 and accuracy: 67.39
For epoch number: 84, train loss: 1.18441374231093 and accuracy: 67.39439866883183
For epoch: 84, test loss: 1.189702388606494 and accuracy: 67.4
For epoch number: 85, train loss: 1.1723705234499318 and accuracy: 67.65746496891678
For epoch: 85, test loss: 1.1893230322041088 and accuracy: 67.4
For epoch number: 86, train loss: 1.18264274106585 and accuracy: 67.68595703751203
For epoch: 86, test loss: 1.1890963021712968 and accuracy: 67.38
For epoch number: 87, train loss: 1.1789226470485565 and accuracy: 67.60128977989626
For epoch: 87, test loss: 1.188668828221816 and accuracy: 67.38
For epoch number: 88, train loss: 1.1708859700187895 and accuracy: 67.52705746347492
For epoch: 88, test loss: 1.1883226044570343 and accuracy: 67.4
For epoch number: 89, train loss: 1.164788065456119 and accuracy: 67.78976818545163
For epoch: 89, test loss: 1.188368809374073 and accuracy: 67.4
For epoch number: 90, train loss: 1.176841639174093 and accuracy: 67.57962548015365
For epoch: 90, test loss: 1.1883740387385404 and accuracy: 67.42
For epoch number: 91, train loss: 1.174115770587734 and accuracy: 67.62488312411722
For epoch: 91, test loss: 1.1884150067462196 and accuracy: 67.42
For epoch number: 92, train loss: 1.1702685330225073 and accuracy: 67.6774555359718
For epoch: 92, test loss: 1.1884158381932899 and accuracy: 67.44
For epoch number: 93, train loss: 1.1843255364824605 and accuracy: 67.38542867363567
For epoch: 93, test loss: 1.1883917669706707 and accuracy: 67.44
For epoch number: 94, train loss: 1.1876579114267414 and accuracy: 67.14305758784502
For epoch: 94, test loss: 1.1884002859079386 and accuracy: 67.43
For epoch number: 95, train loss: 1.1774632904789235 and accuracy: 67.26851018735128
For epoch: 95, test loss: 1.188380860075166 and accuracy: 67.43
For epoch number: 96, train loss: 1.1663444962832008 and accuracy: 67.67626316104929
For epoch: 96, test loss: 1.1883607137052319 and accuracy: 67.42
For epoch number: 97, train loss: 1.1694069592426595 and accuracy: 67.62038242066274
For epoch: 97, test loss: 1.1883470951756345 and accuracy: 67.42
For epoch number: 98, train loss: 1.1780983557206544 and accuracy: 67.24356184975672
For epoch: 98, test loss: 1.1883395359485964 and accuracy: 67.42
For epoch number: 99, train loss: 1.1636280519924616 and accuracy: 67.73568317148224
For epoch: 99, test loss: 1.188338967818248 and accuracy: 67.42
Test accuracy: 67.42
