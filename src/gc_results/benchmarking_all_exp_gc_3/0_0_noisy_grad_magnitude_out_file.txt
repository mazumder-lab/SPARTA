Namespace(dataset='cifar10', batch_size=1000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=100, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=True, magnitude_descending=False, type_mask='noisy_grad_magnitude', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=1.0, experiment_dir='benchmarking_all_exp_gc_3', out_file='benchmarking_all_exp_gc_3/0_0_noisy_grad_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_3/0_0_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=0, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=5.4296875 and C=1.0
For epoch number: 0, train loss: 1.876642983772851 and accuracy: 37.241531457451714
For epoch: 0, test loss: 1.4254138409336912 and accuracy: 53.88
For epoch number: 1, train loss: 1.3635937589587588 and accuracy: 54.73206611900622
For epoch: 1, test loss: 1.3273546212836156 and accuracy: 56.47
For epoch number: 2, train loss: 1.302378052219921 and accuracy: 57.187035623920636
For epoch: 2, test loss: 1.2906623052645334 and accuracy: 58.5
For epoch number: 3, train loss: 1.2898293486956893 and accuracy: 59.05352270903547
For epoch: 3, test loss: 1.301294808900809 and accuracy: 59.82
For epoch number: 4, train loss: 1.2981715062350938 and accuracy: 60.025984409354386
For epoch: 4, test loss: 1.287333538260641 and accuracy: 60.96
For epoch number: 5, train loss: 1.2912479674383057 and accuracy: 62.07957792921521
For epoch: 5, test loss: 1.2988762123675286 and accuracy: 62.39
For epoch number: 6, train loss: 1.2914956045150756 and accuracy: 63.28406310302982
For epoch: 6, test loss: 1.295353348496594 and accuracy: 63.85
For epoch number: 7, train loss: 1.2859719270697008 and accuracy: 64.18541872318137
For epoch: 7, test loss: 1.2910869332808483 and accuracy: 64.5
For epoch number: 8, train loss: 1.2545526510898743 and accuracy: 65.53027273454371
For epoch: 8, test loss: 1.2686728322053258 and accuracy: 65.51
For epoch number: 9, train loss: 1.2629373180502244 and accuracy: 66.02662929222144
For epoch: 9, test loss: 1.279480443725103 and accuracy: 66.07
For epoch number: 10, train loss: 1.2576300810799146 and accuracy: 67.00191474352515
For epoch: 10, test loss: 1.2617016864728323 and accuracy: 67.0
For epoch number: 11, train loss: 1.2580534954903475 and accuracy: 67.18597275139136
For epoch: 11, test loss: 1.2596144608304471 and accuracy: 67.3
For epoch number: 12, train loss: 1.248025666604232 and accuracy: 67.7581009044263
For epoch: 12, test loss: 1.2446488994586318 and accuracy: 68.26
For epoch number: 13, train loss: 1.2351632529726395 and accuracy: 68.5434861351471
For epoch: 13, test loss: 1.2574955451337597 and accuracy: 68.43
For epoch number: 14, train loss: 1.2367025567147567 and accuracy: 69.15792424121086
For epoch: 14, test loss: 1.2462503178210198 and accuracy: 69.26
For epoch number: 15, train loss: 1.2022601512519533 and accuracy: 69.88035753389207
For epoch: 15, test loss: 1.239835410178462 and accuracy: 69.51
For epoch number: 16, train loss: 1.220023740329454 and accuracy: 69.77844311377245
For epoch: 16, test loss: 1.2223348240309124 and accuracy: 69.97
For epoch number: 17, train loss: 1.19046079096469 and accuracy: 70.35637578553815
For epoch: 17, test loss: 1.2290426168260695 and accuracy: 70.12
For epoch number: 18, train loss: 1.2095483030268543 and accuracy: 70.81135943003841
For epoch: 18, test loss: 1.2221853046477595 and accuracy: 70.92
For epoch number: 19, train loss: 1.1932113681360377 and accuracy: 71.36921250494657
For epoch: 19, test loss: 1.2174480134927774 and accuracy: 71.15
For epoch number: 20, train loss: 1.1942515103644087 and accuracy: 71.49615730112785
For epoch: 20, test loss: 1.2194110253189183 and accuracy: 71.24
For epoch number: 21, train loss: 1.2032023988535938 and accuracy: 71.59254807692308
For epoch: 21, test loss: 1.212175047850307 and accuracy: 71.69
For epoch number: 22, train loss: 1.1882943903085397 and accuracy: 71.9130504211745
For epoch: 22, test loss: 1.2046207476265822 and accuracy: 71.87
For epoch number: 23, train loss: 1.1751090644654774 and accuracy: 72.23946340975073
For epoch: 23, test loss: 1.1959774645068977 and accuracy: 72.23
For epoch number: 24, train loss: 1.1867326482045697 and accuracy: 72.50798369117676
For epoch: 24, test loss: 1.1924418090265008 and accuracy: 72.27
For epoch number: 25, train loss: 1.1780090152760576 and accuracy: 72.49924812030075
For epoch: 25, test loss: 1.1823605555522292 and accuracy: 72.58
For epoch number: 26, train loss: 1.1874762527222904 and accuracy: 72.61821593245374
For epoch: 26, test loss: 1.1895798142952254 and accuracy: 72.87
For epoch number: 27, train loss: 1.1526313992540809 and accuracy: 73.31965729455774
For epoch: 27, test loss: 1.1874542334411717 and accuracy: 72.9
For epoch number: 28, train loss: 1.1755909877891106 and accuracy: 73.25996371393823
For epoch: 28, test loss: 1.1938375762746305 and accuracy: 73.02
For epoch number: 29, train loss: 1.197913049393103 and accuracy: 73.18907243710251
For epoch: 29, test loss: 1.2040102708188793 and accuracy: 73.24
For epoch number: 30, train loss: 1.1983993791128746 and accuracy: 73.52565127057696
For epoch: 30, test loss: 1.2108256658421288 and accuracy: 73.69
For epoch number: 31, train loss: 1.2048767987352151 and accuracy: 73.65963612944775
For epoch: 31, test loss: 1.2184255892717386 and accuracy: 73.79
For epoch number: 32, train loss: 1.206739787340621 and accuracy: 74.01352649271651
For epoch: 32, test loss: 1.2147594622418851 and accuracy: 73.75
For epoch number: 33, train loss: 1.1927065035996547 and accuracy: 74.27228925257835
For epoch: 33, test loss: 1.2157603517363342 and accuracy: 73.9
For epoch number: 34, train loss: 1.2278480341320945 and accuracy: 74.04143321436405
For epoch: 34, test loss: 1.212177038192749 and accuracy: 74.26
For epoch number: 35, train loss: 1.2072144161560796 and accuracy: 74.2825761357963
For epoch: 35, test loss: 1.2160754852657076 and accuracy: 74.5
For epoch number: 36, train loss: 1.2171609529835707 and accuracy: 74.15229567766156
For epoch: 36, test loss: 1.2004033825065517 and accuracy: 74.59
For epoch number: 37, train loss: 1.1911384932853524 and accuracy: 74.59154590341616
For epoch: 37, test loss: 1.195868431767331 and accuracy: 74.86
For epoch number: 38, train loss: 1.2035687619676956 and accuracy: 74.2407221664995
For epoch: 38, test loss: 1.1898125568522682 and accuracy: 74.6
For epoch number: 39, train loss: 1.1570335388183595 and accuracy: 75.0125237952109
For epoch: 39, test loss: 1.1842568720443338 and accuracy: 75.04
For epoch number: 40, train loss: 1.2013421604647139 and accuracy: 74.52332003063651
For epoch: 40, test loss: 1.1936768285835846 and accuracy: 74.87
For epoch number: 41, train loss: 1.1662966995641137 and accuracy: 75.3410491985841
For epoch: 41, test loss: 1.1983001775379423 and accuracy: 75.09
For epoch number: 42, train loss: 1.1777136381361422 and accuracy: 75.05740470818441
For epoch: 42, test loss: 1.1921531467498103 and accuracy: 75.47
For epoch number: 43, train loss: 1.1764432347685325 and accuracy: 75.16980981300944
For epoch: 43, test loss: 1.1882560554938981 and accuracy: 75.22
For epoch number: 44, train loss: 1.1654502091638943 and accuracy: 75.11541829180928
For epoch: 44, test loss: 1.187265209759338 and accuracy: 75.13
For epoch number: 45, train loss: 1.174040040515718 and accuracy: 74.98843174730912
For epoch: 45, test loss: 1.1938284341293046 and accuracy: 75.33
For epoch number: 46, train loss: 1.1731033831610715 and accuracy: 75.14801100924697
For epoch: 46, test loss: 1.192192389995237 and accuracy: 75.59
For epoch number: 47, train loss: 1.1958286277528078 and accuracy: 74.99800415136517
For epoch: 47, test loss: 1.1981457305859915 and accuracy: 75.62
For epoch number: 48, train loss: 1.1577602868988401 and accuracy: 75.84774533690138
For epoch: 48, test loss: 1.1970677851121636 and accuracy: 75.4
For epoch number: 49, train loss: 1.1712751482989803 and accuracy: 75.62963110906948
For epoch: 49, test loss: 1.1865987151483945 and accuracy: 75.59
For epoch number: 50, train loss: 1.1613827219384898 and accuracy: 76.05454617739434
For epoch: 50, test loss: 1.1876470763472062 and accuracy: 75.73
For epoch number: 51, train loss: 1.1507969597591856 and accuracy: 75.73827795411627
For epoch: 51, test loss: 1.1818625436553472 and accuracy: 75.8
For epoch number: 52, train loss: 1.1572812884932255 and accuracy: 75.94538236355616
For epoch: 52, test loss: 1.175670377815826 and accuracy: 75.98
For epoch number: 53, train loss: 1.164844840310002 and accuracy: 76.06067883445405
For epoch: 53, test loss: 1.1772704524329947 and accuracy: 75.99
For epoch number: 54, train loss: 1.1507012123720985 and accuracy: 75.96186516898847
For epoch: 54, test loss: 1.1734257596957534 and accuracy: 76.01
For epoch number: 55, train loss: 1.154631577873777 and accuracy: 76.25305012200488
For epoch: 55, test loss: 1.1664400621305537 and accuracy: 76.05
For epoch number: 56, train loss: 1.130117405976471 and accuracy: 76.438920909382
For epoch: 56, test loss: 1.1638797249975084 and accuracy: 76.24
For epoch number: 57, train loss: 1.119413436025721 and accuracy: 76.36662721418685
For epoch: 57, test loss: 1.1622126336339154 and accuracy: 76.42
For epoch number: 58, train loss: 1.1256868857498608 and accuracy: 76.52018907226406
For epoch: 58, test loss: 1.1690364253671863 and accuracy: 76.12
For epoch number: 59, train loss: 1.1281981294784473 and accuracy: 76.28520700508433
For epoch: 59, test loss: 1.167204291760167 and accuracy: 76.16
For epoch number: 60, train loss: 1.1463979184058786 and accuracy: 76.25074626865671
For epoch: 60, test loss: 1.1603384840337536 and accuracy: 76.24
For epoch number: 61, train loss: 1.1337866416692282 and accuracy: 76.29772972110283
For epoch: 61, test loss: 1.1606059081946747 and accuracy: 76.21
For epoch number: 62, train loss: 1.1127745111218907 and accuracy: 76.63315082130413
For epoch: 62, test loss: 1.1526575677002533 and accuracy: 76.18
For epoch number: 63, train loss: 1.1329476437857111 and accuracy: 76.54697177909223
For epoch: 63, test loss: 1.1486454130728034 and accuracy: 76.23
For epoch number: 64, train loss: 1.122305410272856 and accuracy: 76.53856809276922
For epoch: 64, test loss: 1.148090431207343 and accuracy: 76.05
For epoch number: 65, train loss: 1.1282913417475564 and accuracy: 76.39495293410775
For epoch: 65, test loss: 1.1440197878246066 and accuracy: 76.18
For epoch number: 66, train loss: 1.0949821537767008 and accuracy: 76.917581218123
For epoch: 66, test loss: 1.143911932842641 and accuracy: 76.25
For epoch number: 67, train loss: 1.0881438558442251 and accuracy: 77.06981004340727
For epoch: 67, test loss: 1.1434466416322733 and accuracy: 76.42
For epoch number: 68, train loss: 1.1319973108406947 and accuracy: 76.50645911899221
For epoch: 68, test loss: 1.145680144617829 and accuracy: 76.43
For epoch number: 69, train loss: 1.1138320862109425 and accuracy: 76.83662061806277
For epoch: 69, test loss: 1.1454294520088388 and accuracy: 76.47
For epoch number: 70, train loss: 1.1134542192860843 and accuracy: 77.04764186733756
For epoch: 70, test loss: 1.135699610921401 and accuracy: 76.45
For epoch number: 71, train loss: 1.1118384991017871 and accuracy: 76.8686607018313
For epoch: 71, test loss: 1.1343179050880143 and accuracy: 76.47
For epoch number: 72, train loss: 1.1156210837359646 and accuracy: 76.69912639256232
For epoch: 72, test loss: 1.131418500520006 and accuracy: 76.53
For epoch number: 73, train loss: 1.0897613050256456 and accuracy: 77.14673695982107
For epoch: 73, test loss: 1.126931136167502 and accuracy: 76.53
For epoch number: 74, train loss: 1.0954394069121365 and accuracy: 76.97319768952491
For epoch: 74, test loss: 1.1369641589213022 and accuracy: 76.41
For epoch number: 75, train loss: 1.1238148612411398 and accuracy: 76.79820823340535
For epoch: 75, test loss: 1.1357689130155346 and accuracy: 76.44
For epoch number: 76, train loss: 1.1059374220584282 and accuracy: 77.08919625571323
For epoch: 76, test loss: 1.1320338630223576 and accuracy: 76.57
For epoch number: 77, train loss: 1.0975343020696604 and accuracy: 77.30418652891079
For epoch: 77, test loss: 1.1308386174938347 and accuracy: 76.53
For epoch number: 78, train loss: 1.1093944949275665 and accuracy: 77.04052026013007
For epoch: 78, test loss: 1.1309691075282762 and accuracy: 76.61
For epoch number: 79, train loss: 1.0987852297565988 and accuracy: 77.33279613215149
For epoch: 79, test loss: 1.130896482286574 and accuracy: 76.64
For epoch number: 80, train loss: 1.1128980646001976 and accuracy: 76.97783079829009
For epoch: 80, test loss: 1.1327650154693216 and accuracy: 76.7
For epoch number: 81, train loss: 1.0922994355775373 and accuracy: 77.32688826560045
For epoch: 81, test loss: 1.12754471543469 and accuracy: 76.65
For epoch number: 82, train loss: 1.0857599368532196 and accuracy: 77.32532444051589
For epoch: 82, test loss: 1.1267982781687869 and accuracy: 76.79
For epoch number: 83, train loss: 1.0781683296249027 and accuracy: 77.40042602789276
For epoch: 83, test loss: 1.1255851614324353 and accuracy: 76.83
For epoch number: 84, train loss: 1.0801544125591005 and accuracy: 77.1986841583766
For epoch: 84, test loss: 1.1245294982873941 and accuracy: 76.76
For epoch number: 85, train loss: 1.067782904909945 and accuracy: 77.56852771385894
For epoch: 85, test loss: 1.1232903426206564 and accuracy: 76.85
For epoch number: 86, train loss: 1.086170099416755 and accuracy: 77.26942921638181
For epoch: 86, test loss: 1.1246601758123953 and accuracy: 76.86
For epoch number: 87, train loss: 1.1203993300825243 and accuracy: 77.12687312687312
For epoch: 87, test loss: 1.126171938980682 and accuracy: 76.79
For epoch number: 88, train loss: 1.0806619098164 and accuracy: 77.49043095412807
For epoch: 88, test loss: 1.1268076368525057 and accuracy: 76.87
For epoch number: 89, train loss: 1.0746272237018775 and accuracy: 77.70093867708313
For epoch: 89, test loss: 1.1271085980572277 and accuracy: 76.83
For epoch number: 90, train loss: 1.099956139751518 and accuracy: 77.21764517677171
For epoch: 90, test loss: 1.1276754352110852 and accuracy: 76.79
For epoch number: 91, train loss: 1.0838568525213654 and accuracy: 77.51041833627184
For epoch: 91, test loss: 1.1284633776809596 and accuracy: 76.81
For epoch number: 92, train loss: 1.112323680525756 and accuracy: 76.8955665221474
For epoch: 92, test loss: 1.1290398934219457 and accuracy: 76.79
For epoch number: 93, train loss: 1.0900319966815766 and accuracy: 77.37695078031213
For epoch: 93, test loss: 1.1292948322960092 and accuracy: 76.85
For epoch number: 94, train loss: 1.0884068502091813 and accuracy: 77.637139252168
For epoch: 94, test loss: 1.1288682448713085 and accuracy: 76.87
For epoch number: 95, train loss: 1.1146519145239955 and accuracy: 77.088
For epoch: 95, test loss: 1.12888281933869 and accuracy: 76.87
For epoch number: 96, train loss: 1.06918768457004 and accuracy: 77.7095664693649
For epoch: 96, test loss: 1.1287813556345203 and accuracy: 76.85
For epoch number: 97, train loss: 1.0888818739815087 and accuracy: 77.39135675968899
For epoch: 97, test loss: 1.1287520165684857 and accuracy: 76.86
For epoch number: 98, train loss: 1.0930439202439033 and accuracy: 77.48386710087307
For epoch: 98, test loss: 1.1287420905089076 and accuracy: 76.86
For epoch number: 99, train loss: 1.0763536496409054 and accuracy: 77.56990665787212
For epoch: 99, test loss: 1.1287448247776757 and accuracy: 76.87
Test accuracy: 76.87
