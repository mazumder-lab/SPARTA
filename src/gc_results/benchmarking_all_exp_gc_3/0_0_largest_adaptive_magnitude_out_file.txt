Namespace(dataset='cifar10', batch_size=1000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=100, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=True, magnitude_descending=True, type_mask='magnitude', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=1.0, experiment_dir='benchmarking_all_exp_gc_3', out_file='benchmarking_all_exp_gc_3/0_0_largest_adaptive_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_3/0_0_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=0, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=5.4296875 and C=1.0
For epoch number: 0, train loss: 1.8598547266627552 and accuracy: 37.69679709592668
For epoch: 0, test loss: 1.4105352963073343 and accuracy: 53.97
For epoch number: 1, train loss: 1.3611901585351338 and accuracy: 54.626131798285066
For epoch: 1, test loss: 1.3324245697335353 and accuracy: 55.9
For epoch number: 2, train loss: 1.3129820736218603 and accuracy: 56.53439897184626
For epoch: 2, test loss: 1.306843344169327 and accuracy: 57.62
For epoch number: 3, train loss: 1.3024483433856817 and accuracy: 58.07855881880918
For epoch: 3, test loss: 1.312644612940052 and accuracy: 58.59
For epoch number: 4, train loss: 1.307599445409847 and accuracy: 58.85668598840696
For epoch: 4, test loss: 1.2949142297611962 and accuracy: 59.84
For epoch number: 5, train loss: 1.2994870287054583 and accuracy: 60.59073922340574
For epoch: 5, test loss: 1.3130807318264925 and accuracy: 60.98
For epoch number: 6, train loss: 1.3128908311753047 and accuracy: 61.41802773191159
For epoch: 6, test loss: 1.3122722838498369 and accuracy: 62.13
For epoch number: 7, train loss: 1.3047686017476596 and accuracy: 62.51938999576946
For epoch: 7, test loss: 1.3026626668398893 and accuracy: 62.71
For epoch number: 8, train loss: 1.268479918316719 and accuracy: 63.638726705590656
For epoch: 8, test loss: 1.2792948431606534 and accuracy: 63.82
For epoch number: 9, train loss: 1.2764528669018782 and accuracy: 64.15256782460706
For epoch: 9, test loss: 1.281121256985242 and accuracy: 64.49
For epoch number: 10, train loss: 1.2674107027007717 and accuracy: 65.0226745943767
For epoch: 10, test loss: 1.2714515705651874 and accuracy: 65.29
For epoch number: 11, train loss: 1.2754579909159969 and accuracy: 65.20516247431729
For epoch: 11, test loss: 1.2705114830898334 and accuracy: 65.63
For epoch number: 12, train loss: 1.2681204214041781 and accuracy: 65.70367560444826
For epoch: 12, test loss: 1.2565253173248678 and accuracy: 66.52
For epoch number: 13, train loss: 1.2533733113453938 and accuracy: 66.76057471726969
For epoch: 13, test loss: 1.2724284107172037 and accuracy: 66.79
For epoch number: 14, train loss: 1.2539455968005058 and accuracy: 67.42412108592937
For epoch: 14, test loss: 1.2587291575685333 and accuracy: 67.39
For epoch number: 15, train loss: 1.2142562611567276 and accuracy: 68.26986244102483
For epoch: 15, test loss: 1.2542703951461405 and accuracy: 67.89
For epoch number: 16, train loss: 1.2367941271830596 and accuracy: 68.12175648702595
For epoch: 16, test loss: 1.238825568669959 and accuracy: 68.42
For epoch number: 17, train loss: 1.2060458672543366 and accuracy: 68.97422639408161
For epoch: 17, test loss: 1.2456727110886876 and accuracy: 68.63
For epoch number: 18, train loss: 1.2209584621369725 and accuracy: 69.45809866863023
For epoch: 18, test loss: 1.244022778317898 and accuracy: 69.19
For epoch number: 19, train loss: 1.2042926174997162 and accuracy: 70.10684606252474
For epoch: 19, test loss: 1.2288330310507665 and accuracy: 69.75
For epoch number: 20, train loss: 1.2007117245260996 and accuracy: 70.25052400439165
For epoch: 20, test loss: 1.2356518725805645 and accuracy: 70.04
For epoch number: 21, train loss: 1.2099050562650706 and accuracy: 70.5829326923077
For epoch: 21, test loss: 1.233191742172724 and accuracy: 70.24
For epoch number: 22, train loss: 1.1977712769245468 and accuracy: 71.07469360054293
For epoch: 22, test loss: 1.2318649148639245 and accuracy: 70.47
For epoch number: 23, train loss: 1.2015811159497216 and accuracy: 71.1282410651717
For epoch: 23, test loss: 1.2216627409186545 and accuracy: 71.1
For epoch number: 24, train loss: 1.20292288715812 and accuracy: 71.50173733153909
For epoch: 24, test loss: 1.2099093319494514 and accuracy: 71.32
For epoch number: 25, train loss: 1.177417254310915 and accuracy: 71.64711779448622
For epoch: 25, test loss: 1.1965957585769365 and accuracy: 71.56
For epoch number: 26, train loss: 1.1898661969967608 and accuracy: 71.66210902413222
For epoch: 26, test loss: 1.2071288597734668 and accuracy: 71.63
For epoch number: 27, train loss: 1.1566363997671134 and accuracy: 72.44278186718152
For epoch: 27, test loss: 1.211910479430911 and accuracy: 71.73
For epoch number: 28, train loss: 1.1889998641366977 and accuracy: 72.27306258348784
For epoch: 28, test loss: 1.2111185555216633 and accuracy: 71.86
For epoch number: 29, train loss: 1.1934719766398996 and accuracy: 72.26510939562418
For epoch: 29, test loss: 1.219715675975703 and accuracy: 72.0
For epoch number: 30, train loss: 1.1942291054662189 and accuracy: 72.89435831868308
For epoch: 30, test loss: 1.210141065754468 and accuracy: 72.5
For epoch number: 31, train loss: 1.1933555368047495 and accuracy: 72.95524070198036
For epoch: 31, test loss: 1.216414641730393 and accuracy: 72.68
For epoch number: 32, train loss: 1.1898871150966805 and accuracy: 73.18913078277573
For epoch: 32, test loss: 1.2047879235653938 and accuracy: 72.74
For epoch number: 33, train loss: 1.176355516751304 and accuracy: 73.34647393780114
For epoch: 33, test loss: 1.2102448789379265 and accuracy: 72.54
For epoch number: 34, train loss: 1.2056209040823438 and accuracy: 73.05644727134967
For epoch: 34, test loss: 1.2094463864459266 and accuracy: 72.83
For epoch number: 35, train loss: 1.1957354192296132 and accuracy: 73.4917623564653
For epoch: 35, test loss: 1.20822119335585 and accuracy: 73.23
For epoch number: 36, train loss: 1.200549400470536 and accuracy: 73.4094878641264
For epoch: 36, test loss: 1.1980744200416757 and accuracy: 73.48
For epoch number: 37, train loss: 1.1881244613381234 and accuracy: 73.57392316647264
For epoch: 37, test loss: 1.199077282525316 and accuracy: 73.49
For epoch number: 38, train loss: 1.1914549570817214 and accuracy: 73.38214643931795
For epoch: 38, test loss: 1.1906981566284276 and accuracy: 73.72
For epoch number: 39, train loss: 1.152943652524398 and accuracy: 74.18294760044084
For epoch: 39, test loss: 1.1867579463162 and accuracy: 73.88
For epoch number: 40, train loss: 1.1839780607278743 and accuracy: 73.89043415165074
For epoch: 40, test loss: 1.1857223714454264 and accuracy: 74.0
For epoch number: 41, train loss: 1.1565059380549374 and accuracy: 74.45809966988824
For epoch: 41, test loss: 1.1805323815043969 and accuracy: 73.94
For epoch number: 42, train loss: 1.1557602824593678 and accuracy: 74.38651837949004
For epoch: 42, test loss: 1.1724266636220715 and accuracy: 74.09
For epoch number: 43, train loss: 1.1591379229576533 and accuracy: 74.38069362314208
For epoch: 43, test loss: 1.1691802906084665 and accuracy: 73.99
For epoch number: 44, train loss: 1.1490850802156862 and accuracy: 74.41295868821142
For epoch: 44, test loss: 1.1691957810257054 and accuracy: 74.08
For epoch number: 45, train loss: 1.1492103540329706 and accuracy: 74.67458002213057
For epoch: 45, test loss: 1.1697597050968604 and accuracy: 74.34
For epoch number: 46, train loss: 1.1513227173932512 and accuracy: 74.55794705265033
For epoch: 46, test loss: 1.1630188981189002 and accuracy: 74.5
For epoch number: 47, train loss: 1.1634159434516476 and accuracy: 74.51101708446431
For epoch: 47, test loss: 1.1648390368570256 and accuracy: 74.52
For epoch number: 48, train loss: 1.1264661893958137 and accuracy: 75.17474138275352
For epoch: 48, test loss: 1.1590779393534116 and accuracy: 74.64
For epoch number: 49, train loss: 1.1360902867122664 and accuracy: 75.02646348039706
For epoch: 49, test loss: 1.1537322530263587 and accuracy: 74.7
For epoch number: 50, train loss: 1.1271999277018958 and accuracy: 75.440305331372
For epoch: 50, test loss: 1.1629951581170288 and accuracy: 74.68
For epoch number: 51, train loss: 1.1289735107348233 and accuracy: 75.09944152035035
For epoch: 51, test loss: 1.1591044264503672 and accuracy: 74.79
For epoch number: 52, train loss: 1.1303495759044895 and accuracy: 75.24762401251152
For epoch: 52, test loss: 1.1526889936833442 and accuracy: 75.0
For epoch number: 53, train loss: 1.1289601893597887 and accuracy: 75.58037143772015
For epoch: 53, test loss: 1.1507344547706315 and accuracy: 74.81
For epoch number: 54, train loss: 1.1221753374735515 and accuracy: 75.48617912177963
For epoch: 54, test loss: 1.1479230651372596 and accuracy: 75.06
For epoch number: 55, train loss: 1.114964172899381 and accuracy: 75.85903436137446
For epoch: 55, test loss: 1.141492369054239 and accuracy: 74.88
For epoch number: 56, train loss: 1.1027354415385955 and accuracy: 75.87455971821966
For epoch: 56, test loss: 1.1337199497826491 and accuracy: 75.09
For epoch number: 57, train loss: 1.0957707542316995 and accuracy: 75.89119139802203
For epoch: 57, test loss: 1.1383932376209693 and accuracy: 75.13
For epoch number: 58, train loss: 1.0987504613559058 and accuracy: 76.0014420765903
For epoch: 58, test loss: 1.1413659823091724 and accuracy: 75.07
For epoch number: 59, train loss: 1.1015283184014764 and accuracy: 75.99063836655637
For epoch: 59, test loss: 1.1413984698585318 and accuracy: 75.15
For epoch number: 60, train loss: 1.1167628108203866 and accuracy: 75.67562189054726
For epoch: 60, test loss: 1.1328920397577407 and accuracy: 75.27
For epoch number: 61, train loss: 1.1048598267434897 and accuracy: 75.83689103459282
For epoch: 61, test loss: 1.130207921885237 and accuracy: 75.25
For epoch number: 62, train loss: 1.0746434838934378 and accuracy: 76.28272772523644
For epoch: 62, test loss: 1.1300365366513216 and accuracy: 75.45
For epoch number: 63, train loss: 1.1163975137843978 and accuracy: 76.04309812590867
For epoch: 63, test loss: 1.1291842928415612 and accuracy: 75.53
For epoch number: 64, train loss: 1.0993222401915974 and accuracy: 76.09530217279456
For epoch: 64, test loss: 1.1262344114388092 and accuracy: 75.36
For epoch number: 65, train loss: 1.1023809055487315 and accuracy: 76.08451832565592
For epoch: 65, test loss: 1.1196017687833761 and accuracy: 75.63
For epoch number: 66, train loss: 1.0668512591827075 and accuracy: 76.30832126059259
For epoch: 66, test loss: 1.1194989545435845 and accuracy: 75.65
For epoch number: 67, train loss: 1.0647521924972534 and accuracy: 76.43861256023257
For epoch: 67, test loss: 1.1180256227903729 and accuracy: 75.67
For epoch number: 68, train loss: 1.090173329192709 and accuracy: 76.28781192329295
For epoch: 68, test loss: 1.120418521422374 and accuracy: 75.64
For epoch number: 69, train loss: 1.0794133191629676 and accuracy: 76.61303202108121
For epoch: 69, test loss: 1.1159375219405452 and accuracy: 75.73
For epoch number: 70, train loss: 1.0754406808449601 and accuracy: 76.56842777844335
For epoch: 70, test loss: 1.108891175517553 and accuracy: 75.74
For epoch number: 71, train loss: 1.0743377002864454 and accuracy: 76.58171093796705
For epoch: 71, test loss: 1.106293356116814 and accuracy: 75.97
For epoch number: 72, train loss: 1.076417819575499 and accuracy: 76.46469503887153
For epoch: 72, test loss: 1.1029532959189596 and accuracy: 75.98
For epoch number: 73, train loss: 1.0656448198500135 and accuracy: 76.7113986740155
For epoch: 73, test loss: 1.1005911751638484 and accuracy: 76.08
For epoch number: 74, train loss: 1.0622269060788498 and accuracy: 76.80330981552176
For epoch: 74, test loss: 1.108316253257703 and accuracy: 76.09
For epoch number: 75, train loss: 1.0837500547444014 and accuracy: 76.60793213485819
For epoch: 75, test loss: 1.1105805793894996 and accuracy: 76.08
For epoch number: 76, train loss: 1.0873209205190493 and accuracy: 76.56627347663813
For epoch: 76, test loss: 1.107001927834523 and accuracy: 76.19
For epoch number: 77, train loss: 1.0707497425065748 and accuracy: 76.97109918822427
For epoch: 77, test loss: 1.105625434766842 and accuracy: 76.11
For epoch number: 78, train loss: 1.0791270604911651 and accuracy: 76.60830415207604
For epoch: 78, test loss: 1.0993572526340243 and accuracy: 76.25
For epoch number: 79, train loss: 1.0655342570994042 and accuracy: 76.92586623690572
For epoch: 79, test loss: 1.096681244765656 and accuracy: 76.37
For epoch number: 80, train loss: 1.077395957062453 and accuracy: 76.64777810915598
For epoch: 80, test loss: 1.097411191916164 and accuracy: 76.34
For epoch number: 81, train loss: 1.0580556340642853 and accuracy: 77.24334109128523
For epoch: 81, test loss: 1.0947136026394517 and accuracy: 76.37
For epoch number: 82, train loss: 1.0513651940317554 and accuracy: 77.0581381333119
For epoch: 82, test loss: 1.0949808925012998 and accuracy: 76.5
For epoch number: 83, train loss: 1.047814507995333 and accuracy: 77.2014790402315
For epoch: 83, test loss: 1.0953060954431943 and accuracy: 76.44
For epoch number: 84, train loss: 1.0447375603524365 and accuracy: 77.02429550949229
For epoch: 84, test loss: 1.0919658088985877 and accuracy: 76.42
For epoch number: 85, train loss: 1.0398730476925657 and accuracy: 77.13253401154576
For epoch: 85, test loss: 1.088394764103467 and accuracy: 76.38
For epoch number: 86, train loss: 1.0397032292192967 and accuracy: 77.26942921638181
For epoch: 86, test loss: 1.0890156038199799 and accuracy: 76.43
For epoch number: 87, train loss: 1.0818747774737092 and accuracy: 76.76723276723277
For epoch: 87, test loss: 1.08926392054256 and accuracy: 76.4
For epoch number: 88, train loss: 1.051118952260827 and accuracy: 77.2504610991016
For epoch: 88, test loss: 1.0898265348205083 and accuracy: 76.43
For epoch number: 89, train loss: 1.044522624377531 and accuracy: 77.20868126831019
For epoch: 89, test loss: 1.0890053691743296 and accuracy: 76.43
For epoch number: 90, train loss: 1.0664655222692563 and accuracy: 77.06366981282994
For epoch: 90, test loss: 1.0894620735434037 and accuracy: 76.45
For epoch number: 91, train loss: 1.0546193883652422 and accuracy: 77.0676390447187
For epoch: 91, test loss: 1.090032865729513 and accuracy: 76.44
For epoch number: 92, train loss: 1.0663206951112183 and accuracy: 76.72773770753831
For epoch: 92, test loss: 1.089865911610519 and accuracy: 76.49
For epoch number: 93, train loss: 1.0488956227756683 and accuracy: 77.29891956782713
For epoch: 93, test loss: 1.0901076416426068 and accuracy: 76.49
For epoch number: 94, train loss: 1.0528789931101816 and accuracy: 76.97222166589894
For epoch: 94, test loss: 1.0898152733150916 and accuracy: 76.5
For epoch number: 95, train loss: 1.0738144638633007 and accuracy: 76.782
For epoch: 95, test loss: 1.0897125835660137 and accuracy: 76.51
For epoch number: 96, train loss: 1.0358732270059132 and accuracy: 77.36162214045753
For epoch: 96, test loss: 1.089685515512394 and accuracy: 76.5
For epoch number: 97, train loss: 1.0504474285811243 and accuracy: 77.24268177525968
For epoch: 97, test loss: 1.0896483169326299 and accuracy: 76.51
For epoch number: 98, train loss: 1.0628388143406315 and accuracy: 77.22614029129123
For epoch: 98, test loss: 1.0896724839753742 and accuracy: 76.5
For epoch number: 99, train loss: 1.049151478256759 and accuracy: 77.1961383941956
For epoch: 99, test loss: 1.0896779502494425 and accuracy: 76.5
Test accuracy: 76.5
