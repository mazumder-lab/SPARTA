Namespace(dataset='cifar10', batch_size=1000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=100, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=False, magnitude_descending=False, type_mask='', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=1.0, experiment_dir='benchmarking_all_exp_gc_3', out_file='benchmarking_all_exp_gc_3/0_0_smallest_fixed_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_3/0_0_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=0, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=5.4296875 and C=1.0
For epoch number: 0, train loss: 1.876642983772851 and accuracy: 37.241531457451714
For epoch: 0, test loss: 1.4254138409336912 and accuracy: 53.88
For epoch number: 1, train loss: 1.3635937589587588 and accuracy: 54.73206611900622
For epoch: 1, test loss: 1.3273546212836156 and accuracy: 56.47
For epoch number: 2, train loss: 1.302378052219921 and accuracy: 57.187035623920636
For epoch: 2, test loss: 1.2906623052645334 and accuracy: 58.5
For epoch number: 3, train loss: 1.2898293486956893 and accuracy: 59.05352270903547
For epoch: 3, test loss: 1.301294808900809 and accuracy: 59.82
For epoch number: 4, train loss: 1.2981715062350938 and accuracy: 60.025984409354386
For epoch: 4, test loss: 1.287333538260641 and accuracy: 60.96
For epoch number: 5, train loss: 1.2912479674383057 and accuracy: 62.07957792921521
For epoch: 5, test loss: 1.2988762123675286 and accuracy: 62.39
For epoch number: 6, train loss: 1.2914956045150756 and accuracy: 63.28406310302982
For epoch: 6, test loss: 1.295353348496594 and accuracy: 63.85
For epoch number: 7, train loss: 1.2859719270697008 and accuracy: 64.18541872318137
For epoch: 7, test loss: 1.2910869332808483 and accuracy: 64.5
For epoch number: 8, train loss: 1.2545526510898743 and accuracy: 65.53027273454371
For epoch: 8, test loss: 1.2686728322053258 and accuracy: 65.51
For epoch number: 9, train loss: 1.2629373180502244 and accuracy: 66.02662929222144
For epoch: 9, test loss: 1.279480443725103 and accuracy: 66.07
For epoch number: 10, train loss: 1.260329927189899 and accuracy: 67.0160233800262
For epoch: 10, test loss: 1.267720955836622 and accuracy: 67.16
For epoch number: 11, train loss: 1.2658932636539668 and accuracy: 67.46125152101494
For epoch: 11, test loss: 1.271264902398556 and accuracy: 67.56
For epoch number: 12, train loss: 1.2550358266712818 and accuracy: 68.13344780082656
For epoch: 12, test loss: 1.256014203723473 and accuracy: 68.83
For epoch number: 13, train loss: 1.2435323019440359 and accuracy: 68.9036905863887
For epoch: 13, test loss: 1.2722100894662398 and accuracy: 68.92
For epoch number: 14, train loss: 1.247674090716675 and accuracy: 69.41018659405782
For epoch: 14, test loss: 1.264367151109478 and accuracy: 69.6
For epoch number: 15, train loss: 1.2105306490607883 and accuracy: 70.36410327872116
For epoch: 15, test loss: 1.2520846943312054 and accuracy: 69.97
For epoch number: 16, train loss: 1.2234726874950026 and accuracy: 70.16766467065868
For epoch: 16, test loss: 1.238034366052362 and accuracy: 70.23
For epoch number: 17, train loss: 1.2042830728671767 and accuracy: 70.84559700898895
For epoch: 17, test loss: 1.2469123858439772 and accuracy: 70.5
For epoch number: 18, train loss: 1.218989681586821 and accuracy: 71.49396007880753
For epoch: 18, test loss: 1.2415600366230253 and accuracy: 71.36
For epoch number: 19, train loss: 1.2049333018771673 and accuracy: 72.03601108033241
For epoch: 19, test loss: 1.236031887651999 and accuracy: 71.78
For epoch number: 20, train loss: 1.2012253263751969 and accuracy: 72.21079948098613
For epoch: 20, test loss: 1.2375866189787659 and accuracy: 71.97
For epoch number: 21, train loss: 1.2130116661921513 and accuracy: 72.04727564102564
For epoch: 21, test loss: 1.23452130525927 and accuracy: 72.29
For epoch number: 22, train loss: 1.195658958683449 and accuracy: 72.73743462812887
For epoch: 22, test loss: 1.2304753819598426 and accuracy: 72.1
For epoch number: 23, train loss: 1.1836804483050392 and accuracy: 73.08239062969267
For epoch: 23, test loss: 1.2180067459239234 and accuracy: 72.66
For epoch number: 24, train loss: 1.1921112403787415 and accuracy: 73.24911124947278
For epoch: 24, test loss: 1.2151989514314676 and accuracy: 72.63
For epoch number: 25, train loss: 1.1827913761367286 and accuracy: 72.99248120300751
For epoch: 25, test loss: 1.2057879416248467 and accuracy: 72.81
For epoch number: 26, train loss: 1.187434156042225 and accuracy: 73.09327531487655
For epoch: 26, test loss: 1.2158261077313484 and accuracy: 73.03
For epoch number: 27, train loss: 1.1723807614052157 and accuracy: 73.77820682997466
For epoch: 27, test loss: 1.2215088130552558 and accuracy: 73.47
For epoch number: 28, train loss: 1.1868567680498228 and accuracy: 73.76238610762206
For epoch: 28, test loss: 1.2250688325000714 and accuracy: 73.35
For epoch number: 29, train loss: 1.1996939089614005 and accuracy: 73.73705051797928
For epoch: 29, test loss: 1.2275644887851764 and accuracy: 73.67
For epoch number: 30, train loss: 1.191821793412981 and accuracy: 74.17692184753076
For epoch: 30, test loss: 1.2328075283690343 and accuracy: 73.95
For epoch number: 31, train loss: 1.1958848145145637 and accuracy: 74.46465947512478
For epoch: 31, test loss: 1.2357440870019454 and accuracy: 74.27
For epoch number: 32, train loss: 1.196329599824445 and accuracy: 74.61381463102289
For epoch: 32, test loss: 1.229994973049888 and accuracy: 74.19
For epoch number: 33, train loss: 1.1941426051709487 and accuracy: 74.84171544618326
For epoch: 33, test loss: 1.2336965120291408 and accuracy: 74.31
For epoch number: 34, train loss: 1.207729894660768 and accuracy: 74.84896217574223
For epoch: 34, test loss: 1.2231943577150755 and accuracy: 74.66
For epoch number: 35, train loss: 1.193429498838877 and accuracy: 75.0134797803295
For epoch: 35, test loss: 1.2267295997354049 and accuracy: 74.91
For epoch number: 36, train loss: 1.2025709151077637 and accuracy: 74.65620043765433
For epoch: 36, test loss: 1.2086200736746002 and accuracy: 75.04
For epoch number: 37, train loss: 1.1728200809905451 and accuracy: 75.1736180803661
For epoch: 37, test loss: 1.201351838775828 and accuracy: 75.13
For epoch number: 38, train loss: 1.1770997554063798 and accuracy: 74.88665997993982
For epoch: 38, test loss: 1.1972260822223713 and accuracy: 75.09
For epoch number: 39, train loss: 1.145964188873768 and accuracy: 75.28704538623384
For epoch: 39, test loss: 1.1899812983561167 and accuracy: 75.39
For epoch number: 40, train loss: 1.1767218226861769 and accuracy: 75.15620590962229
For epoch: 40, test loss: 1.185163425493844 and accuracy: 75.64
For epoch number: 41, train loss: 1.1443434613333507 and accuracy: 75.94360259316709
For epoch: 41, test loss: 1.185213989849332 and accuracy: 75.53
For epoch number: 42, train loss: 1.156982979167097 and accuracy: 75.67438052832298
For epoch: 42, test loss: 1.1766212175164041 and accuracy: 75.67
For epoch number: 43, train loss: 1.1628375904250692 and accuracy: 75.6552661019658
For epoch: 43, test loss: 1.1824952914744993 and accuracy: 75.91
For epoch number: 44, train loss: 1.143940595506262 and accuracy: 76.00095518586325
For epoch: 44, test loss: 1.1794817877721182 and accuracy: 75.85
For epoch number: 45, train loss: 1.152476913815453 and accuracy: 75.80122724072025
For epoch: 45, test loss: 1.1793810544134695 and accuracy: 76.0
For epoch number: 46, train loss: 1.1447507861189377 and accuracy: 76.03904718531572
For epoch: 46, test loss: 1.1749047719979588 and accuracy: 76.13
For epoch number: 47, train loss: 1.1576690075532445 and accuracy: 75.96399489062749
For epoch: 47, test loss: 1.1817182030858873 and accuracy: 76.26
For epoch number: 48, train loss: 1.1309943712892987 and accuracy: 76.48879658106003
For epoch: 48, test loss: 1.1805999686446371 and accuracy: 76.28
For epoch number: 49, train loss: 1.134450218313333 and accuracy: 76.29671053945555
For epoch: 49, test loss: 1.1704155795181854 and accuracy: 76.35
For epoch number: 50, train loss: 1.1214109981535056 and accuracy: 76.63698167216634
For epoch: 50, test loss: 1.172364151176018 and accuracy: 76.31
For epoch number: 51, train loss: 1.1149406426201456 and accuracy: 76.37912330748523
For epoch: 51, test loss: 1.168875692765924 and accuracy: 76.55
For epoch number: 52, train loss: 1.13361378713646 and accuracy: 76.3824838593255
For epoch: 52, test loss: 1.1664647890042654 and accuracy: 76.78
For epoch number: 53, train loss: 1.1180058827495758 and accuracy: 76.89521293627922
For epoch: 53, test loss: 1.169763212717032 and accuracy: 76.6
For epoch number: 54, train loss: 1.108072680575507 and accuracy: 76.91323726340615
For epoch: 54, test loss: 1.1631456681444674 and accuracy: 76.65
For epoch number: 55, train loss: 1.1132260262396323 and accuracy: 77.00108004320172
For epoch: 55, test loss: 1.155233249634127 and accuracy: 76.51
