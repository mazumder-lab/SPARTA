Namespace(dataset='cifar10', batch_size=1000, model='resnet18', num_classes=10, lr_schedule_type='onecycle', classifier_lr=0.2, lr=0.01, lsr=0.0, warm_up=0.01, num_epochs=100, optimizer='sgd', momentum=0.9, wd=0.0, clip_gradient=False, grad_clip_cst=0.0, use_adaptive_lr=False, finetune_strategy='all_layers', lora_rank=0, accum_steps=1, print_batch_stat_freq=1, use_gn=True, use_magnitude_mask=True, use_adaptive_magnitude_mask=True, magnitude_descending=False, type_mask='magnitude', sparsity=0.1, use_dp=True, epsilon=1.0, delta=1e-05, clipping=1.0, experiment_dir='benchmarking_all_exp_gc_3', out_file='benchmarking_all_exp_gc_3/0_0_smallest_adaptive_magnitude_out_file.txt', save_file='benchmarking_all_exp_gc_3/0_0_output_net.pt', seed=0, SLURM_JOB_ID=0, TASK_ID=0, local_rank=None, pretrained=True)
The indices of trainable parameters are: [0, 3, 4, 5, 8, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 73, 74, 75, 78, 79, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 98, 99, 100, 101].
The names of trainable parameters are: ['conv1.weight_trainable', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight_trainable', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight_trainable', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight_trainable', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight_trainable', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight_trainable', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight_trainable', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.shortcut.0.weight_trainable', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.1.conv1.weight_trainable', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight_trainable', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight_trainable', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight_trainable', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.shortcut.0.weight_trainable', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.1.conv1.weight_trainable', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight_trainable', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight_trainable', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight_trainable', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.shortcut.0.weight_trainable', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.1.conv1.weight_trainable', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight_trainable', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'linear.weight', 'linear.bias'].
The number of trainable parameters is: 11173962.
Using sigma=5.4296875 and C=1.0
For epoch number: 0, train loss: 1.876642983772851 and accuracy: 37.241531457451714
For epoch: 0, test loss: 1.4254138409336912 and accuracy: 53.88
For epoch number: 1, train loss: 1.3635937589587588 and accuracy: 54.73206611900622
For epoch: 1, test loss: 1.3273546212836156 and accuracy: 56.47
For epoch number: 2, train loss: 1.302378052219921 and accuracy: 57.187035623920636
For epoch: 2, test loss: 1.2906623052645334 and accuracy: 58.5
For epoch number: 3, train loss: 1.2898293486956893 and accuracy: 59.05352270903547
For epoch: 3, test loss: 1.301294808900809 and accuracy: 59.82
For epoch number: 4, train loss: 1.2981715062350938 and accuracy: 60.025984409354386
For epoch: 4, test loss: 1.287333538260641 and accuracy: 60.96
For epoch number: 5, train loss: 1.2912479674383057 and accuracy: 62.07957792921521
For epoch: 5, test loss: 1.2988762123675286 and accuracy: 62.39
For epoch number: 6, train loss: 1.2914956045150756 and accuracy: 63.28406310302982
For epoch: 6, test loss: 1.295353348496594 and accuracy: 63.85
For epoch number: 7, train loss: 1.2859719270697008 and accuracy: 64.18541872318137
For epoch: 7, test loss: 1.2910869332808483 and accuracy: 64.5
For epoch number: 8, train loss: 1.2545526510898743 and accuracy: 65.53027273454371
For epoch: 8, test loss: 1.2686728322053258 and accuracy: 65.51
For epoch number: 9, train loss: 1.2629373180502244 and accuracy: 66.02662929222144
For epoch: 9, test loss: 1.279480443725103 and accuracy: 66.07
For epoch number: 10, train loss: 1.260355738422165 and accuracy: 67.0039302630253
For epoch: 10, test loss: 1.2670044808448115 and accuracy: 67.11
For epoch number: 11, train loss: 1.2655714220973526 and accuracy: 67.50713131595221
For epoch: 11, test loss: 1.2690881204001512 and accuracy: 67.59
For epoch number: 12, train loss: 1.2542633932274705 and accuracy: 68.0835346497095
For epoch: 12, test loss: 1.2523336033277874 and accuracy: 68.7
For epoch number: 13, train loss: 1.2420927290733044 and accuracy: 68.8916166941683
For epoch: 13, test loss: 1.267612779442268 and accuracy: 68.92
For epoch number: 14, train loss: 1.2493966354896093 and accuracy: 69.34011371826699
For epoch: 14, test loss: 1.260343390175059 and accuracy: 69.47
For epoch number: 15, train loss: 1.2128144836155363 and accuracy: 70.30040013536917
For epoch: 15, test loss: 1.2550104916850222 and accuracy: 69.87
For epoch number: 16, train loss: 1.2270607371411386 and accuracy: 70.0938123752495
For epoch: 16, test loss: 1.2405354984198944 and accuracy: 70.17
For epoch number: 17, train loss: 1.2085939198732376 and accuracy: 70.80582292578156
For epoch: 17, test loss: 1.2520388553414163 and accuracy: 70.16
For epoch number: 18, train loss: 1.219271869541798 and accuracy: 71.49396007880753
For epoch: 18, test loss: 1.248551590533196 and accuracy: 71.17
For epoch number: 19, train loss: 1.2060338669577562 and accuracy: 71.97863078749505
For epoch: 19, test loss: 1.2392670399026027 and accuracy: 71.61
For epoch number: 20, train loss: 1.1993828131497362 and accuracy: 72.17486775127259
For epoch: 20, test loss: 1.237909054454369 and accuracy: 71.74
For epoch number: 21, train loss: 1.2118855639579875 and accuracy: 72.13741987179488
For epoch: 21, test loss: 1.237199046943761 and accuracy: 71.8
For epoch number: 22, train loss: 1.1972503982795961 and accuracy: 72.66757155974291
For epoch: 22, test loss: 1.2334026234059394 and accuracy: 71.92
For epoch number: 23, train loss: 1.1843224628766378 and accuracy: 72.95024526979678
For epoch: 23, test loss: 1.2214965360074104 and accuracy: 72.53
For epoch number: 24, train loss: 1.194351757851597 and accuracy: 73.1848400249051
For epoch: 24, test loss: 1.2191550912736338 and accuracy: 72.51
For epoch number: 25, train loss: 1.1856585640560164 and accuracy: 72.99448621553884
For epoch: 25, test loss: 1.207880576200123 and accuracy: 72.69
For epoch number: 26, train loss: 1.1904373497333167 and accuracy: 73.01942154534022
For epoch: 26, test loss: 1.220196856728083 and accuracy: 73.04
For epoch number: 27, train loss: 1.1743605726013773 and accuracy: 73.81843047343229
For epoch: 27, test loss: 1.2221470799627183 and accuracy: 73.24
For epoch number: 28, train loss: 1.186031593317325 and accuracy: 73.71254261618517
For epoch: 28, test loss: 1.2235120195376723 and accuracy: 73.24
For epoch number: 29, train loss: 1.2017197184507769 and accuracy: 73.64305427782888
For epoch: 29, test loss: 1.2237297402152532 and accuracy: 73.68
For epoch number: 30, train loss: 1.197272420269455 and accuracy: 74.18491289755474
For epoch: 30, test loss: 1.2274712580668776 and accuracy: 73.98
For epoch number: 31, train loss: 1.1965635802883368 and accuracy: 74.43245854129769
For epoch: 31, test loss: 1.2345244975029668 and accuracy: 74.05
For epoch number: 32, train loss: 1.197783058287997 and accuracy: 74.63182327517208
For epoch: 32, test loss: 1.2273488452162924 and accuracy: 74.19
For epoch number: 33, train loss: 1.1955234028455866 and accuracy: 74.61075936765819
For epoch: 33, test loss: 1.2303490525559535 and accuracy: 74.21
For epoch number: 34, train loss: 1.2109465244270505 and accuracy: 74.59374314597332
For epoch: 34, test loss: 1.2268949996066998 and accuracy: 74.31
For epoch number: 35, train loss: 1.1904449080531958 and accuracy: 75.17124313529706
For epoch: 35, test loss: 1.2264398540122599 and accuracy: 74.78
For epoch number: 36, train loss: 1.2030459905540187 and accuracy: 74.68229909056232
For epoch: 36, test loss: 1.212304871293563 and accuracy: 74.98
For epoch number: 37, train loss: 1.1786115014530276 and accuracy: 75.06523222672715
For epoch: 37, test loss: 1.207774264148519 and accuracy: 74.99
For epoch number: 38, train loss: 1.1845539259222837 and accuracy: 75.01303911735205
For epoch: 38, test loss: 1.204424659662609 and accuracy: 74.95
For epoch number: 39, train loss: 1.146146835730626 and accuracy: 75.3531710249474
For epoch: 39, test loss: 1.2000638714319543 and accuracy: 75.3
For epoch number: 40, train loss: 1.1861123090545183 and accuracy: 75.0876768654009
For epoch: 40, test loss: 1.1968745747699012 and accuracy: 75.31
For epoch number: 41, train loss: 1.1495081041798447 and accuracy: 75.85013721512946
For epoch: 41, test loss: 1.194452490233168 and accuracy: 75.54
For epoch number: 42, train loss: 1.1591807522247952 and accuracy: 75.68037058482918
For epoch: 42, test loss: 1.1869841368892524 and accuracy: 75.57
For epoch number: 43, train loss: 1.1671254128672695 and accuracy: 75.68723030206169
For epoch: 43, test loss: 1.1886536426182035 and accuracy: 75.55
For epoch number: 44, train loss: 1.1499898048974715 and accuracy: 75.80792804266497
For epoch: 44, test loss: 1.1885244793529752 and accuracy: 75.69
For epoch number: 45, train loss: 1.1564768305846622 and accuracy: 75.8273815511518
For epoch: 45, test loss: 1.1872578127474724 and accuracy: 75.9
For epoch number: 46, train loss: 1.147472341033749 and accuracy: 75.91628220105736
For epoch: 46, test loss: 1.1796959993205494 and accuracy: 75.88
For epoch number: 47, train loss: 1.1608065222794155 and accuracy: 75.99592846878492
For epoch: 47, test loss: 1.1830774100520942 and accuracy: 76.03
For epoch number: 48, train loss: 1.132584331205913 and accuracy: 76.49878180293166
For epoch: 48, test loss: 1.180140663551379 and accuracy: 76.25
For epoch number: 49, train loss: 1.1356892495838469 and accuracy: 76.24877668817032
For epoch: 49, test loss: 1.1747030065029482 and accuracy: 76.32
For epoch number: 50, train loss: 1.1254652322922079 and accuracy: 76.68071403013558
For epoch: 50, test loss: 1.1755906486813026 and accuracy: 76.67
For epoch number: 51, train loss: 1.1130723002219292 and accuracy: 76.48760496604926
For epoch: 51, test loss: 1.1666727616817136 and accuracy: 76.61
For epoch number: 52, train loss: 1.1272447916842598 and accuracy: 76.57697397441552
For epoch: 52, test loss: 1.1621286190008815 and accuracy: 76.67
For epoch number: 53, train loss: 1.1178362105638926 and accuracy: 76.92523214857509
For epoch: 53, test loss: 1.1652662437173384 and accuracy: 76.64
For epoch number: 54, train loss: 1.109957005693799 and accuracy: 76.95720824255991
For epoch: 54, test loss: 1.1626721786547312 and accuracy: 76.5
For epoch number: 55, train loss: 1.112745849739753 and accuracy: 76.99507980319213
For epoch: 55, test loss: 1.1551199661025517 and accuracy: 76.66
For epoch number: 56, train loss: 1.091619721004135 and accuracy: 77.31748318924112
For epoch: 56, test loss: 1.1462177324898635 and accuracy: 76.75
For epoch number: 57, train loss: 1.0920399191714965 and accuracy: 77.26935344741118
For epoch: 57, test loss: 1.1461476796790013 and accuracy: 76.82
For epoch number: 58, train loss: 1.095284471662277 and accuracy: 77.2492389040218
For epoch: 58, test loss: 1.1494188489793222 and accuracy: 76.87
For epoch number: 59, train loss: 1.0914296614641399 and accuracy: 77.32426761359051
For epoch: 59, test loss: 1.1471501022954531 and accuracy: 76.83
For epoch number: 60, train loss: 1.11080404149212 and accuracy: 77.05472636815921
For epoch: 60, test loss: 1.1444019471542746 and accuracy: 76.73
For epoch number: 61, train loss: 1.1073125277343692 and accuracy: 77.05980928061285
For epoch: 61, test loss: 1.141488816164717 and accuracy: 76.94
For epoch number: 62, train loss: 1.0854791762928169 and accuracy: 77.58287705326033
For epoch: 62, test loss: 1.1426784456530703 and accuracy: 76.78
For epoch number: 63, train loss: 1.1059910998114566 and accuracy: 77.18029913763917
For epoch: 63, test loss: 1.1423971811427345 and accuracy: 76.48
For epoch number: 64, train loss: 1.1001579246534416 and accuracy: 77.28064273558397
For epoch: 64, test loss: 1.1447323432451562 and accuracy: 76.67
For epoch number: 65, train loss: 1.101268827290762 and accuracy: 77.38433807330263
For epoch: 65, test loss: 1.1398345563985124 and accuracy: 76.7
For epoch number: 66, train loss: 1.0756820659144328 and accuracy: 77.44944333088571
For epoch: 66, test loss: 1.1423959732055664 and accuracy: 76.81
For epoch number: 67, train loss: 1.0586774575142632 and accuracy: 77.74481303014615
For epoch: 67, test loss: 1.1408143005793607 and accuracy: 76.9
For epoch number: 68, train loss: 1.100763110876541 and accuracy: 77.34494102543529
For epoch: 68, test loss: 1.1465158952942378 and accuracy: 76.9
For epoch number: 69, train loss: 1.0822473125717111 and accuracy: 77.47744150762597
For epoch: 69, test loss: 1.1405371759511247 and accuracy: 77.2
For epoch number: 70, train loss: 1.089650045875354 and accuracy: 77.56679046363963
For epoch: 70, test loss: 1.1343453254880784 and accuracy: 77.18
For epoch number: 71, train loss: 1.0697945341100277 and accuracy: 77.6478090189905
For epoch: 71, test loss: 1.1280426092540161 and accuracy: 77.21
For epoch number: 72, train loss: 1.0725136644967639 and accuracy: 77.65889236194599
For epoch: 72, test loss: 1.1254021208497542 and accuracy: 77.21
For epoch number: 73, train loss: 1.061475943837847 and accuracy: 77.8676411853982
For epoch: 73, test loss: 1.1198721150808697 and accuracy: 77.59
For epoch number: 74, train loss: 1.0604468170454293 and accuracy: 77.76467531429256
For epoch: 74, test loss: 1.1236953603315958 and accuracy: 77.46
For epoch number: 75, train loss: 1.0852721599595887 and accuracy: 77.51372564565041
For epoch: 75, test loss: 1.125529942255986 and accuracy: 77.54
For epoch number: 76, train loss: 1.0740509709137926 and accuracy: 77.77578188930802
For epoch: 76, test loss: 1.1275871580914607 and accuracy: 77.63
For epoch number: 77, train loss: 1.0630624668226496 and accuracy: 78.04415900432814
For epoch: 77, test loss: 1.1255468605439873 and accuracy: 77.58
For epoch number: 78, train loss: 1.0698567220500408 and accuracy: 77.91295647823912
For epoch: 78, test loss: 1.1223749439173107 and accuracy: 77.59
For epoch number: 79, train loss: 1.0581032623485045 and accuracy: 78.10838033843675
For epoch: 79, test loss: 1.1230407123324238 and accuracy: 77.68
For epoch number: 80, train loss: 1.0728927233146623 and accuracy: 77.8586340590516
For epoch: 80, test loss: 1.1254567405845546 and accuracy: 77.59
For epoch number: 81, train loss: 1.063597180698583 and accuracy: 78.19418750372978
For epoch: 81, test loss: 1.1240699193145656 and accuracy: 77.61
For epoch number: 82, train loss: 1.0492427663038706 and accuracy: 78.2634898951344
For epoch: 82, test loss: 1.1248634465133087 and accuracy: 77.57
For epoch number: 83, train loss: 1.0426409282570794 and accuracy: 78.33889313130501
For epoch: 83, test loss: 1.123236981373799 and accuracy: 77.51
For epoch number: 84, train loss: 1.0489034304269274 and accuracy: 78.17763861915897
For epoch: 84, test loss: 1.1191685671293283 and accuracy: 77.51
For epoch number: 85, train loss: 1.038982162244932 and accuracy: 78.33959065035727
For epoch: 85, test loss: 1.1162221597719797 and accuracy: 77.61
For epoch number: 86, train loss: 1.04704673640056 and accuracy: 78.2872460496614
For epoch: 86, test loss: 1.115391046940526 and accuracy: 77.62
For epoch number: 87, train loss: 1.0905182929102946 and accuracy: 77.87012987012987
For epoch: 87, test loss: 1.1162376090695587 and accuracy: 77.61
For epoch number: 88, train loss: 1.0451396244314481 and accuracy: 78.26190428970907
For epoch: 88, test loss: 1.1166294583036929 and accuracy: 77.58
For epoch number: 89, train loss: 1.0356049050242846 and accuracy: 78.46822249237698
For epoch: 89, test loss: 1.1161781685261787 and accuracy: 77.65
For epoch number: 90, train loss: 1.065782538977743 and accuracy: 78.19548872180451
For epoch: 90, test loss: 1.1170000396197355 and accuracy: 77.62
For epoch number: 91, train loss: 1.045410101450336 and accuracy: 78.17959608911684
For epoch: 91, test loss: 1.1179853383498857 and accuracy: 77.65
For epoch number: 92, train loss: 1.0632070644863705 and accuracy: 78.19024594913189
For epoch: 92, test loss: 1.1181399776965757 and accuracy: 77.66
For epoch number: 93, train loss: 1.0483321069535756 and accuracy: 78.2312925170068
For epoch: 93, test loss: 1.118429036834572 and accuracy: 77.63
For epoch number: 94, train loss: 1.0488787181532702 and accuracy: 78.24998497927139
For epoch: 94, test loss: 1.1180264180219626 and accuracy: 77.64
For epoch number: 95, train loss: 1.0743154587051593 and accuracy: 77.922
For epoch: 95, test loss: 1.1181529632097558 and accuracy: 77.6
For epoch number: 96, train loss: 1.0348077151888893 and accuracy: 78.3454647256439
For epoch: 96, test loss: 1.1181947558741026 and accuracy: 77.6
For epoch number: 97, train loss: 1.052605324194207 and accuracy: 78.14477728889156
For epoch: 97, test loss: 1.1182225825665872 and accuracy: 77.6
For epoch number: 98, train loss: 1.056039433919221 and accuracy: 78.22508141370147
For epoch: 98, test loss: 1.1182429707503017 and accuracy: 77.6
For epoch number: 99, train loss: 1.043356647607924 and accuracy: 78.44136635286122
For epoch: 99, test loss: 1.118248252551767 and accuracy: 77.59
Test accuracy: 77.59
