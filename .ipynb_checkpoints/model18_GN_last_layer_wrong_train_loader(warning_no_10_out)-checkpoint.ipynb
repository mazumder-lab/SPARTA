{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72120713-676b-4d71-addd-a33b276d85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from math import floor\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "import torch.cuda\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "\n",
    "from dataset_utils import get_train_and_test_dataloader\n",
    "from models.resnet import ResNet50, ResNet18\n",
    "from models.wide_resnet import Wide_ResNet\n",
    "from optimizers.optimizer_utils import use_optimizer, use_lr_scheduler\n",
    "import opacus\n",
    "from opacus.validators import ModuleValidator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7c3423-fb33-424f-a491-60365678b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18(num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1773f83a-9e2a-4144-ade9-120a9d704f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "net = ModuleValidator.fix(net.to(\"cpu\"))  # Note that we are using the backbone as a black-box featurizer. It's never trained, so we can keep BatchNorms in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b75f500-ee74-416e-9878-04e6ed9d01ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"./model18_100_GN-Copy1.pt\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c789ba77-0006-4ee1-b32c-04c8458e7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b04ec84a-9994-481f-854c-fc8c47926bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIF100_MEAN = [0.5071, 0.4867, 0.4408]\n",
    "CIF100_STD = [0.2675, 0.2565, 0.2761]\n",
    "batch_size = 100\n",
    "\n",
    "train_ds = CIFAR100('../datasets/', \n",
    "                   train=True, \n",
    "                   download=True, \n",
    "                   transform=Compose([ToTensor(), Normalize(CIF100_MEAN, CIF100_STD)])\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4, \n",
    "                          pin_memory=True,\n",
    ")\n",
    "\n",
    "test_ds = CIFAR100('../datasets/', \n",
    "                  train=False, \n",
    "                  download=True, \n",
    "                  transform=Compose([ToTensor(), Normalize(CIF100_MEAN, CIF100_STD)])\n",
    ")\n",
    "test_loader = DataLoader(test_ds, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False, \n",
    "                         num_workers=2, \n",
    "                         pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a7d985a-4e06-40dd-a3b1-613e26771727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def compute_acc(model, dataloader, device=\"cpu\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f\"The device used is {device}.\", flush=True)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            if len(labels.shape) >= 2:\n",
    "                labels = labels[:, 0]\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            del images, labels, outputs\n",
    "\n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64024873-ce9c-48e9-9f7a-c7f3ff21ede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device used is cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.68"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_acc(net, test_loader, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48345bb6-ac30-44cd-b4d0-4ad27656b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_modules = []\n",
    "\n",
    "for name, module in net.named_children():\n",
    "    if isinstance(module, nn.Sequential):\n",
    "        # Add all submodules of the Sequential module\n",
    "        resnet_modules.extend(module)\n",
    "    else:\n",
    "        # Add the non-Sequential module\n",
    "        resnet_modules.append(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1b273f1-2e23-4f0d-b6a1-39fe46a057c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = nn.Sequential(*resnet_modules[:-1])\n",
    "head = nn.Sequential(nn.Flatten(), nn.Linear(512, 10))\n",
    "\n",
    "backbone = backbone.eval()\n",
    "head = head.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8373f0d-77cd-4b96-9605-f66547509965",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(head.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a38e1389-b92f-4fdc-aa56-1de7791a8b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/mmakni/.conda/envs/pruning/lib/python3.9/site-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/home/gridsan/mmakni/.conda/envs/pruning/lib/python3.9/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/home/gridsan/mmakni/.conda/envs/pruning/lib/python3.9/site-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ConstantLR, LambdaLR\n",
    "epochs = 200\n",
    "\n",
    "privacy_engine = opacus.PrivacyEngine()\n",
    "(\n",
    "model,\n",
    "optimizer,\n",
    "train_loader,\n",
    ") = privacy_engine.make_private_with_epsilon(\n",
    "module=head,\n",
    "optimizer=optimizer,\n",
    "data_loader=train_loader,\n",
    "epochs=epochs,\n",
    "target_epsilon=0.5,\n",
    "target_delta=1e-5,\n",
    "max_grad_norm=1,\n",
    ")\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=int(1.2*epochs), eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec8fc196-5fe9-4b1c-bd62-949cba7c4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def train(backbone, head, criterion, optimizer, train_loader, warmup_scheduler, cosine_scheduler):\n",
    "  accs = []\n",
    "  losses = []\n",
    "  for x, y in tqdm(train_loader):\n",
    "    x = x.to('cuda')\n",
    "    y = y.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "      x = backbone(x)\n",
    "\n",
    "    logits = head(x)\n",
    "    loss = criterion(logits, y)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()    \n",
    "    \n",
    "    preds = logits.argmax(-1)\n",
    "    n_correct = float(preds.eq(y).sum())\n",
    "    batch_accuracy = n_correct / len(y)\n",
    "\n",
    "    accs.append(batch_accuracy)\n",
    "    losses.append(float(loss))\n",
    "\n",
    "  print(\n",
    "      f\"Train Accuracy: {mean(accs):.6f}\"\n",
    "      f\"Train Loss: {mean(losses):.6f}\"\n",
    "  ) \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b427a4-467a-4563-91ae-6c776e97f534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pruning)",
   "language": "python",
   "name": "pruning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
